{
  "key": "7U6GVXP7",
  "url": "https://www.cs.ox.ac.uk/isg/conferences/tmp-proceedings/NeSy2023/paper5.pdf",
  "text": [
    "Exploring Mathematical Conjecturing with Large\nLanguage Models\nMoa Johansson\n1\n,  Nicholas Smallbone\n1\n1\nChalmers University of Technology, Gothenburg, Sweden\nAbstract\nThe task of automating the discovery of mathematical conjectures has so far primarily been addressed\nin symbolic systems. However, a neuro-symbolic architecture seems like an excellent fit for this task.\nWe can assign the generative task to a neural system without much risk, even if a few non-theorems\nslip through, the results are checked afterwards using a symbolic theorem prover or counter-example\nfinder. In this initial case-study, we investigate the capabilities of GPT-3.5 and GPT-4 on this task. While\nresults are mixed, we see potential in improving on the weaknesses of purely symbolic systems.  A\nneuro-symbolic theory exploration system could, for instance, add some more variation in conjectures\nover purely symbolic systems while not missing obvious candidates.\nKeywords\nTheory Exploration, Conjecturing, Large Language Models\n1.  Introduction\nWe are interested in the problem of inventing new conjectures about a set of functions and\ndatatypes, known astheory explorationorautomated conjecturing. In this paper we discuss the\npotential of using a large language model (LLM) as part of a neuro-symbolic theory exploration\nsystem and conduct some initial experiments.\nThe problem of mathematical discovery has a long history in symbolic AI research with early\nsystems based on specialised heuristics such as AM and Graffiti [1,2], on to later works like HR\n(discovery of integer sequences) and MATHsAiD (algebra) [3,4]. Our own research has focused\non theory exploration for finding auxiliary lemmas for automating proofs by induction, or for\ninvestigating the properties of a functional program [5,6]. We have studied this extensively\nusing symbolic and heuristic methods, which perform well at generating relevant and interesting\nlemmas. What is considered interesting and relevant of course depend on context: typically\na lemma is considered interesting if its proof is non-trivial, given current knowledge.  We\nhave built several systems, e.g. QuickSpec [7], which discovers equational conjectures and its\nextension, Hipster [8], which also searches for proofs in the proof assistant Isabelle/HOL. These\nsystem run on a regular laptop, are fast and perform well for small to moderate sized inputs (up\nto around 10 different functions, and term sizes up to 7–9 symbols on each side of the equation).\nNeSy 2023, 17th International Workshop on Neural-Symbolic Learning and Reasoning, Certosa di Pontignano, Siena,\nItaly\n$moa.johansson@chalmers.se (M. Johansson); nicsma@chalmers.se (N. Smallbone)\n\u001a0000-0002-1097-8278 (M. Johansson); 0000-0003-2880-6121 (N. Smallbone)\n©2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\nCEUR\nWorkshop\nProceedings\nhttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings (CEUR-WS.org)",
    "Given larger theories, or asked for larger term sizes, the increased search space usually requires\nmore computing power than a laptop to run quickly.  Furthermore, the number of possible\nconjectures increases a lot, so the system tends to produce too many conjectures, and many of\nthe conjectures are uninteresting. One solution to this was suggested in [9], where the user\nprovides a set of templates describing the shapes of conjectures to explore, thus restricting the\nsearch space to lemmas which the user thinks has an appealing shape. We now want to take\nthis one step further: can common templates be extracted from data? Could we even use a large\nlanguage model to generate conjectures by analogy to previously seen mathematical statements\ndirectly?\nAs a case study, we investigate the capabilities of ChatGPT and its underlying LLMs, GPT-3\nand GPT-4 [10,11], on this task. We limit ourselves to generating conjectures and proofs in the\nsyntax of the proof assistant Isabelle/HOL, which we can then run to check for validity. For\nIsabelle/HOL, there is prior work using various LLMs to generate formal versions of natural\nlanguage statements [12,13], as well as proof scripts [14,15], but none of these have considered\nconjecture generation based on function and datatype definitions.  Neural conjecturing has\nhowever been attempted for other systems, for instance Mizar [16], where a GPT-2 model is\ntrained on the Mizar Mathematical Library. With a medium temperature setting, they managed\nto generate some novel and interesting lemmas, while lower settings repeated existing lemmas,\nand higher settings tended towards outputs in inconsistent or unparsable syntax.  Another\nexample is the skip-tree transformer model trained on data for the HOL Light proof assistant\n[17]. Here, between 10–30% of the generated conjectures were both true and novel, while the\nreminder consisted of instances of theorems from the training data, or false conjectures.\n2.  Case-study: GPT-4 as a Theory Exploration System\nAs a first experiment, we wanted to investigate the basic theory exploration capabilities of\nGPT-4, zero-shot, without any further fine-tuning.  How good is it, given an Isabelle theory\nfile, at generating interesting properties and proofs? How does it compare to symbolic systems\nsuch as Hipster? Has it been able to extract common patterns for equational statements? GPT-4\nwas at the time of writing only available via ChatGPT, so our experiments took the form of\nconversations with ChatGPT.\nCaveat:GPT-4 has been trained on large amounts of code from GitHub. We found evidence\n(see Appendix B) that it has also been trained on the GitHub repositories of our symbolic theory\nexploration tools QuickSpec and Hipster, as it can produce output in exactly the same syntax as\nour tools. Likewise, it appears to have been trained on all the online libraries and proof archives\nof the Isabelle/HOL proof assistant. This makes it difficult to evaluate how good GPT-4 really is.\nTo what extent is it generalising to suggest plausible lemmas and proof structures, or simply\nrecalling a training example it has already seen?\n2.1.  Insertion sort\nWe started with the following Isabelle theory defining an insertion sort function, taken from\nHipster:",
    "theory Sorted\nimports Main\nbegin\nfunsorted :: \"int list => bool\"\nwhere\n\"sorted [] = True\"\n| \"sorted [x] = True\"\n| \"sorted (x # y # xs) = (x <= y /\\ sorted (y#xs))\"\nfunins :: \"int => int list => int list\"\nwhere\n\"ins x [] = [x]\"\n| \"ins x (y#ys) = (if x <= y then (x#y#ys) else (y#(ins x ys)))\"\nfunisort :: \"int list => int list\"\nwhere\n\"isort [] = []\"\n| \"isort (x#xs) = ins x (isort xs)\"\nend\nThe aim is to discover and prove thatisortproduces a sorted list. The proof requires a key\nlemma, also to be discovered, that inserting into a sorted list preserves its sortedness. Hipster\ncan discover both lemmas and prove them automatically by structural induction.\nWe prompted GPT-4 with the Isabelle theory, followed by the sentence “Generate some\nlemmas about sorted, insert and isort, in Isabelle syntax.”  It responded with a syntactically-\ncorrect list of Isabelle lemmas and proofs, shown in full in Appendix A. Here we show an excerpt:\nthe list of discovered lemmas, together with the proof of the lemmasorted (isort xs).\nsorted [x] = True\nsorted xs ==> sorted (ins x xs)\nsorted (isort xs)\nlength (ins x xs) = length xs + 1\nlength (isort xs) = length xs\ncount_list (ins x xs) a = count_list xs a +\n(if x = a then 1 else 0)\ncount_list (isort xs) a = count_list xs a\nlemmaisort_sorted [simp]: \"sorted (isort xs)\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons a xs)\nthen show ?case by (simp add: ins_sorted)\nqed\nFigure 1:The lemmas produced by GPT-4 for the insertion sort example, and its proof of lemma\nisort_sorted.\nThe lemmas are all correct and useful, and include the theorem that insertion sort produces\na sorted list, the key lemmains_lengthused in that proof, and other lemmas involving\nstandard Isabelle functions such aslength. All of the proofs are correct except for the key\nlemmains_sorted, i.e.sorted xs ==> sorted (ins x xs).  That proof follows the\ncorrect structure (induction and two case splits), and most of the reasoning is correct, but one\nstep is false (and can be removed) and two have incorrect justifications.",
    "Performance of other LLMs:We also ran the experiment using a few other large language\nmodels. We did not have much success running the experiment using Codex, the variant of\nGPT-3.5 specifically designed for code generation, nor with any of the smaller versions of\nGPT-3.5 (ada, babbage, curie), but the largest version davinci produced good results.  It did\nproduce useful lemmas, but more of the proofs were incorrect compared to GPT-4. We also\nbriefly experimented with the web interface of the open source BLOOM model\n1\n[18]. Due to its\nlimited output size (64 tokens) it could only generate one lemma (in greedy mode) with proof:\n(sorted (isort xs)) = True, and the proof was not correct. A more thorough evaluation\nof additional models is further work.\n2.2.  Functional geometry\nAs GPT-4 has most likely seen the lists theory already, we decided to test it on a lesser-known\ntheory,functional geometry[19]. It defines functions for building and combiningdrawings:\n•blankrepresents a blank drawing;\n•over d1 d2superimposesd1andd2;\n•beside d1 d2drawsd1next tod2;\n•above d1 d2drawsd1aboved2;\n•rot ddrawsdrotated clockwise by 90 degrees;\n•rot45 ddrawsdrotated clockwise by 45 degrees;\n•flip ddrawsdflipped horizontally.\nWe previously tested functional geometry using QuickSpec [7], which was able to discover\nmany relevant lemmas. It has not to our knowledge been formalised in Isabelle before.\nWe prompted ChatGPT with the Isabelle theory file followed by the text “Generate lemmas\nin Isabelle format about the functions blank, over, beside, above, rot, flip and rot45.  Do not\nprove the lemmas – use ‘sorry’.\n2\n” It produced a list of syntactically correct Isabelle lemmas,\neach followed correctly by “sorry”. However, the output varies drastically from run to run.\nHere are the lemmas suggested by one run of GPT-4 – we have indicated which lemmas\nare correct by putting a star next to them. Notice that in this run, it mostly suggests “generic”\nlemmas such as associativity, commutativity and distributivity:\n(*) over blank blank = blank\n(*) over (over A B) C = over A (over B C)\n(*) over A B = over B A\nbeside (beside A B) C =\nbeside A (beside B C)\nabove (above A B) C =\nabove A (above B C)\nrot (rot A) = A\n(*) flip (flip A) = A\n(*) rot45 (rot45 A) = rot A\nrot (flip A) = flip (rot A)\n1\nhttps://huggingface.co/spaces/huggingface/bloom_demo\n2\nsorryis an Isabelle command that skips a proof. We used it in order to reduce the size of the output, as in this\ncase study, all the proofs can be solved automatically by Isabelle’ssimptactic.",
    "(*) rot (beside A B) =\nabove (rot A) (rot B)\nflip (beside A B) =\nbeside (flip A) (flip B)\n(*) rot45 (over A B) =\nover (rot45 A) (rot45 B)\nrot45 (beside A B) =\nbeside (rot45 A) (rot45 B)\nrot45 (above A B) =\nabove (rot45 A) (rot45 B)\nHere is a more successful run, where the system suggested lemmas specific to drawing, such\nas the fact that rotating a drawing by 45 degrees 8 times is the identity function:\n(*) over blank d = d\n(*) over (over d1 d2) d3 =\nover d1 (over d2 d3)\n(*) over d1 d2 = over d2 d1\nbeside (beside d1 d2) d3 =\nbeside d1 (beside d2 d3)\nabove (above d1 d2) d3 =\nabove d1 (above d2 d3)\n(*) rot (rot (rot (rot d))) = d\n(*) flip (flip d) = d\n(*) rot45 (rot45 (rot45 (rot45 (rot45\n(rot45 (rot45 (rot45 d))))))) = d\nWe found that GPT-4 usually produces the same kind of “generic” lemmas every time: (1)\nBinary functions are associative and commutative, and have the empty drawing as identity\nelement. (2) Pairs of binary functions distribute over one another. (3) Unary functions are their\nown inverse (e.g.rot (rot x) = x), and commute with each other (e.g.rot (flip x) = flip (rot x)).\nExactly which functions have these properties varies from run to run.Most of these generic\nlemmas are false.\nAbout 50% of the time, it also produces useful drawing-specific lemmas such asrot45 (rot45 x)\n= rot xorrot (rot (rot (rot x))) = x. However, it also quite often produces muddled versions of\nthese lemmas, where e.g.rotandrot45swap places or the drawing is rotated the wrong number\nof times. Sometimes it produces two mutually contradictory lemmas. And often lemmas are\nseemingly random combinations of drawing functions.\nWe also note that GPT-4 seems to have learnt useful “templates” for lemmas. For example, the\noutput often states that a binary function is associative, regardless of the function name. This\nsuggests that GPT-4 can be used to suggest lemma templates for theory exploration systems\nsuch as [9].\nTo summarise, GPT-4 is able to find useful lemmas much of the time, but each run gives\na different set of lemmas, so there is not much consistency, and we risk missing interesting\nlemmas.  There are some wrong lemmas, but that is not a problem in a theory exploration\nsystem, since the lemmas will be checked by Isabelle.  By repeatedly running GPT-4, we do\nhowever obtain a useful and descriptive set of lemmas for the drawing theory.\nGPT-4 vs symbolic theory explorationWe also ran the symbolic theory exploration system\nQuickSpec [7] on the drawing theory. The results are shown in Appendix C; all the lemmas\ndiscovered by QuickSpec are correct.\nOn the one hand, QuickSpec covers the space of lemmas much more systematically than\nGPT-4. It discovers all the most important lemmas, e.g.:",
    "•which functions are associative, commutative, etc. (the simple lemma (2)over x x = xis\none that GPT-4 never generated);\n•how functions distribute over each other (e.g. (7)rot (beside y x) = above (rot x) (rot y));\n•rotating a drawing by 90 degrees four times is the identity function (10);\n•equivalent ways to lay out four drawings in a 2x2 grid, (4)above (beside x y) (beside z w)\n= beside (above x z) (above y w).\nOn the other hand, QuickSpec fails to discover important lemmas aboutrot45, such as that\nrotating a document by 45 degrees 8 times is the identity function, and that two 45-degree\nrotations are equivalent to a 90-degree rotation (rot45 (rot45 x) = rot x).  The first lemma is\nbeyond QuickSpec’s term size limit; GPT-4 can generate arbitrarily complex lemmas. Looking\ninto why the second lemma was not discovered, we were surprised to discover that it does not\nhold, because of a bug in the implementation ofrot45! This is an important difference between\nsymbolic and neural theory exploration: a symbolic system can only suggest lemmas that hold\nin the explored theory, whereas a language model can suggest lemmas that perhaps the user\nmightwant to hold, based on its interpretation of what the user meant.  In other words, the\nlanguage model is not overly affected by minor errors in the theory.\nTurning up the temperatureLarge language models have a “temperature” parameter, which\ncontrols how random its output is. At low temperature, outputs are nearly deterministic, and at\nhigh temperature quite unpredictable. We experimented with running ChatGPT at different\ntemperatures, to see whether it might be more “creative” in its lemmas at higher temperature.\nThis experiment used GPT-3.5 rather than GPT-4, since GPT-4 did not allow customising the\ntemperature at the time of writing.\nWe found that reducing the temperature, even to 0, had no noticeable effect on the output.\nIncreasing it from its default of 0.7 to 1, we saw a very slight increase in the variety of laws,\nthough most were the same as before. However, it also started to produce many laws involving\nnon-existent function symbols, such asdist (a,b) = dist (b,c) ==> dist (a,b) =\nsqrt 2 ==> (a,c) in rot45_drawing x a b c\n. Increasing the temperature further, the\noutput became incoherent:theorem [simp]: \"\n<And>w h nvt dvt. below vfinal besiden = above besiden_sym hbesiden_tsh\"\nObscuring the namesWe wanted to see how much GPT-4’s output was influenced by the\nnames of the functions and types. We therefore renamed all the symbols in the drawing theory,\nso that the typeDrawingbecameMonkey,besidebecamehello, and so on. We prompted GPT-4\nto generate lemmas for the program. There was a clear effect: all of the drawing-specific lemmas\n(such asrot (rot (rot (rot x))) = x) disappeared from the output, and only the generic lemmas\n(such as associativity and commutativity) remained. Evidently, the names of the functions are\nhighly significant for GPT-4 – an important difference compared to symbolic methods.\n2.3.  Mathematical theories\nFinally, we tested GPT-4 on some more mathematical theories from the Archive of Formal\nProofs. These do not contain many function definitions, but largely consist of theorems and",
    "proofs. We prompted GPT-4 to suggest useful additional lemmas, but not to provide proofs. We\ntried two theories.\n1.Suppes’ theorem for probability logic\n3\n: Here GPT-4 produced many standard theorems\nfrom probability, giving them appropriate names, such asbayes_theorem. Many lemmas\nwere generalisations of lemmas occurring in the theory file. GPT-4 has most likely not\nbeen trained on this theory (which was added in 2023), but has probably seen probability\ntheory from other sources.\n2.Forcing\n4\n(a topic from set theory): here GPT-4 only produced lemmas that were already\npresent in the theory file (usually even copying the name of the lemma). GPT-4 may have\nseen this theory (which was added in 2020) in its training, but forcing is likely a much\nless common topic than probability in the training data.\nThis suggests that GPT-4 is able to identify related lemmas in domains it recognises, but has\nlittle ability to create new lemmas in domains it is unfamiliar with. By contrast, symbolic theory\nexploration systems can explore new and unfamiliar theories just as well as familiar ones.\n3.  Discussion\nTheory exploration seems like a domain where a neuro-symbolic architecture would be a perfect\nfit. So far most work in conjecture discovery has been using symbolic systems based on heuristic\nsearch over type-correct terms, then passed to a (symbolic) theorem proving system. The task\nof conjecturing can however benefit from the capabilities of LLMs of recognising patterns and\neffectively suggesting conjectures by analogy. Hallucinations are not a severe problem, as long\nas enough conjectures are true and interesting: if the LLM produces some conjectures that are\nfalse, they will be caught by the theorem prover or counter-example checker.\nGPT-4 used as a theory explorer has some desirable features, some of which are missing from\nsymbolic systems:\nNames are informative.\nA LLM pays attention to the actual names of functions and types,\nand can thus occasionally mix in an additional function the user had not thought of, but\nwhich often makes sense to include.\nLess restricted syntax.The neural system is less restricted than the symbolic system with\nrespect to the shape of the lemmas.  It can generate both equalities and implications,\nwithout being explicitly instructed to.\nAbility to recognise common patterns.We also noticed that GPT-4 had a tendency to sug-\ngest common algebraic patterns which we expect to see, e.g. associativity for most binary\nfunctions. If the search space is large, focusing on such properties can be advantageous.\nProperties of buggy functions.We notice that even for a function containing a subtle bug,\nGPT-4 produced sensible conjectures, that probablyoughtto hold.  If these match the\n3\nhttps://www.isa-afp.org/entries/Suppes_Theorem.html\n4\nhttps://www.isa-afp.org/entries/Forcing.html",
    "user’s expectation, but the proof assistant can find a counter-example, they serve as good\nindications of a bug being present. A symbolic system, like QuickSpec, would instead\ngenerate other properties (or none at all), that do hold about the buggy function. This\nmay be harder for the user to make sense of.\nThere are however also some disadvantages of using GPT-4 and LLMs in general for conjecture\ngeneration:\nDifficulty of fair evaluation.The system is hidden behind a proprietary API, so we do not\nexactly know how it works. It is also impossible to know exactly what has been seen\nalready during training to quantify which results are due to genuine capabilities of analogy\nformation, and which ones are repeating examples seen during training.\nCoverage.The LLM tends to generate a limited number of conjectures, and as it is stochastic,\nit may well produce different conjectures on different runs.  A symbolic system like\nQuickSpec, on the other hand, systematically explores the space of possible lemmas, and\nthe user has control over the search strategy and will know what ought to be generated\n(or skipped). A neural system provides no such structure – the user cannot get an idea of\nhow well the space of possible conjectures has been covered.\nHardware and energy consumption.A symbolic system like QuickSpec comfortably runs\non a regular laptop and requires no prior training.  GPT-4 on the other hand requires\nspecialised hardware and consumes much more energy to train and query. How much\nbetter performance should we require for this much higher energy cost?\nPayment.GPT-4 is a commercial product, and access costs money. It is questionable if a niche\napplication like conjecture discovery for theorem proving is something anyone wants to\npay for in the long run.\nIt is certainly interesting to continue investigations into integrating large language models in\ntheory explorations, as they do have many desirable features, not covered by fully symbolic\nsystems. From a research point of view, it would be desirable to work with a more transparent\nmodel, enabling more scientific evaluation practices.  However, we noticed that we had the\nmost success with generalisation and reasoning by analogy when using the largest models,\nGPT-3.5 davinci and GPT-4.  Possibly, lemma generation thus benefits both from the larger\nunderlying neural network, and having access to a large context window. Further experiments\nin systematically comparing also additional open source LLMs, are planned for further work.\nAnother open question is whether a smaller, carefully trained network could perform the task\nequally well.\nIn some cases the symbolic and neural systems produce complementary sets of conjectures.\nOne option is to run both systems in combination, using the symbolic system to produce a\nreliable baseline set of lemmas, and the neural system for creativity.  A more sophisticated\napproach is to run both systems in combination, using the output of the symbolic system as part\nof a prompt to a fine-tuned neural system, giving the neural system some more information\nabout a new theory.",
    "References\n[1]D. B. Lenat, AM, an artificial intelligence approach to discovery in mathematics as heuristic\nsearch, 1976.\n[2]S. Fajtlowicz, On conjectures of Graffiti, Annals of Discrete Mathematics 38 (1988) 113–118.\n[3]S. Colton,  The HR program for theorem generation,  in: A. Voronkov (Ed.), Automated\nDeduction—CADE-18, Springer Berlin Heidelberg, Berlin, Heidelberg, 2002, pp. 285–289.\n[4]R. L. McCasland, A. Bundy, P. F. Smith,  MATHsAiD: Automated mathematical theory\nexploration, Applied Intelligence (2017). URL: https://doi.org/10.1007/s10489-017-0954-8.\ndoi:10.1007/s10489-017-0954-8.\n[5]M. Johansson, L. Dixon, A. Bundy, Conjecture synthesis for inductive theories, Journal of\nAutomated Reasoning 47 (2011) 251–289. URL: https://doi.org/10.1007/s10817-010-9193-y.\ndoi:10.1007/s10817-010-9193-y.\n[6]K. Claessen, M. Johansson, D. Rosén, N. Smallbone, Automating inductive proofs using\ntheory exploration, in: Proceedings of the Conference on Automated Deduction (CADE),\nvolume 7898 ofLNCS, Springer, 2013, pp. 392–406.\n[7]N.  Smallbone,  M.  Johansson,  K.  Claessen,  M.  Algehed,Quick  specifications  for\nthe busy programmer,   Journal of Functional Programming 27 (2017). doi:10.1017/\nS0956796817000090.\n[8]\nM. Johansson, D. Rosén, N. Smallbone, K. Claessen, Hipster: Integrating theory exploration\nin a proof assistant, in: Proceedings of CICM, Springer, 2014, pp. 108–122.\n[9]S. H. Einarsdóttir, N. Smallbone, M. Johansson, Template-based theory exploration: Dis-\ncovering properties of functional programs by testing, in: Proceedings of IFL’20, 2021.\n[10]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,\nP. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan,\nR. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin,\nS. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, D. Amodei,\nLanguage models are few-shot learners, in: H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan,\nH. Lin (Eds.), Advances in Neural Information Processing Systems, volume 33, Curran\nAssociates, Inc., 2020, pp. 1877–1901. URL: https://proceedings.neurips.cc/paper/2020/file/\n1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\n[11]OpenAI, GPT-4 Technical Report, Technical Report, 2023. URL: https://cdn.openai.com/\npapers/gpt-4.pdf .\n[12]A. Lewkowycz, A. J. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. V. Ramasesh,\nA. Slone, C. Anil, I. Schlag, T. Gutman-Solo, Y. Wu, B. Neyshabur, G. Gur-Ari, V. Misra,\nSolving quantitative reasoning problems with language models, in: A. H. Oh, A. Agarwal,\nD. Belgrave, K. Cho (Eds.), Advances in Neural Information Processing Systems, 2022. URL:\nhttps://openreview.net/forum?id=IFXTZERXdM7.\n[13]Y. Wu, A. Q. Jiang, W. Li, M. N. Rabe, C. E. Staats, M. Jamnik, C. Szegedy, Autoformalization\nwith large language models, in: A. H. Oh, A. Agarwal, D. Belgrave, K. Cho (Eds.), Advances\nin Neural Information Processing Systems, 2022. URL: https://openreview.net/forum?id=\nIUikebJ1Bf0.\n[14]\nA. Q. Jiang, W. Li, S. Tworkowski, K. Czechowski, T. Odrzygóźdź, P. Miłoś, Y. Wu, M. Jamnik,\nThor: Wielding hammers to integrate language models and automated theorem provers,",
    "in:  A. H. Oh, A. Agarwal, D. Belgrave, K. Cho (Eds.), Advances in Neural Information\nProcessing Systems, 2022. URL: https://openreview.net/forum?id=fUeOyt-2EOp.\n[15]E. First, M. N. Rabe, T. Ringer, Y. Brun, Baldur: Whole-proof generation and repair with\nlarge language models, 2023. URL: https://arxiv.org/abs/2303.04910. doi:10.48550/ARXIV.\n2303.04910.\n[16]\nJ. Urban, J. Jakubův, First neural conjecturing datasets and experiments, in: C. Benzmüller,\nB. Miller (Eds.), Intelligent Computer Mathematics, Springer International Publishing,\nCham, 2020, pp. 315–323.\n[17]\nM. N. Rabe, D. Lee, K. Bansal, C. Szegedy,  Mathematical reasoning via self-supervised\nskip-tree training, in: International Conference on Learning Representations, 2021. URL:\nhttps://openreview.net/forum?id=YmqAnY0CMEy.\n[18]T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ilić, D. Hesslow, R. Castagné, A. S. Luccioni,\nF. Yvon, M. Gallé, et al.,  Bloom: A 176b-parameter open-access multilingual language\nmodel, arXiv preprint arXiv:2211.05100 (2022).\n[19]P. Henderson, Functional geometry, Higher-Order and Symbolic Computation 15 (2002)\n349–365.",
    "A.  Output of GPT-4 on the insertion sort theory\nlemmasorted_single [simp]: \"sorted [x] = True\"\nby simp\nlemmains_sorted [simp]: \"sorted xs ==> sorted (ins x xs)\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons a xs)\nthen show ?case\nproof(cases xs)\ncase Nil\nthen show ?thesis by simp\nnext\ncase (Cons b xs)\nthen show ?thesis\nproof(cases \"x <le> a\")\ncase True\nthen show ?thesis by (simp add: Cons)\nnext\ncase False\nthen have \"ins x (a # b # xs) = a # ins x (b # xs)\" by simp\nalso have \"... = a # b # ins x xs\" using Cons by simp\nfinally show ?thesis using Cons by (simp add: sorted.simps(3))\nqed\nqed\nqed\nlemmaisort_sorted [simp]: \"sorted (isort xs)\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons a xs)\nthen show ?case by (simp add: ins_sorted)\nqed\nlemmains_length [simp]: \"length (ins x xs) = length xs + 1\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp",
    "next\ncase (Cons a xs)\nthen show ?case by (simp split: if_splits)\nqed\nlemmaisort_length [simp]: \"length (isort xs) = length xs\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons a xs)\nthen show ?case by (simp add: ins_length)\nqed\nlemmains_permutes [simp]: \"count_list (ins x xs) a = count_list xs a + (if x = a then 1\nelse 0)\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons b xs)\nthen show ?case by (simp split: if_splits)\nqed\nlemmaisort_permutes [simp]: \"count_list (isort xs) a = count_list xs a\"\nproof(induct xs)\ncase Nil\nthen show ?case by simp\nnext\ncase (Cons b xs)\nthen show ?case by (simp add: ins_permutes)\nqed",
    "B.  ChatGPT mimicking Hipster’s output\nFigure 2:GPT-3.5 mimicking Hipster’s output. Here, ChatGPT has first been presented with an Isabelle\ntheory defining some functions about lists, and then asked to \"Generate some lemmas in Isabelle\nsyntax\". The theory contained the import statementimports \"$HIPSTER_HOME/IsaHipster\",\nwhich activates the theory exploration tool Hipster for Isabelle. We note that it exactly mimics Hipster’s\nnaming scheme for discovered lemmas (lemma_a, lemma_aa, lemma_ab and so on), and that it adds\nthe tag[thy_expl]which Hipster puts on lemmas it has discovered. Furthermore, the proof scripts\nlook very similar to what Hipster would produce using induction, simplification in the base-case and\nthen and calls to automated provers via Sledgehammer to close the step-case. However, note that the\nproof scripts are not quite right, for instance lemma_ab there is a reference to a non-existent lemma\nsorted_Cons.",
    "C.  Output of QuickSpec on the drawing theory\n== Functions ==\nover :: Drawing -> Drawing -> Drawing\n== Laws ==\n1. over x y = over y x\n2. over x x = x\n3. over (over x y) z = over x (over y z)\n== Functions ==\nbeside :: Drawing -> Drawing -> Drawing\nabove :: Drawing -> Drawing -> Drawing\n== Laws ==\n4. above (beside x y) (beside z w) = beside (above x z) (above y w)\n5. over (above x y) (above z w) = above (over x z) (over y w)\n6. over (beside x y) (beside z w) = beside (over x z) (over y w)\n== Functions ==\nrot :: Drawing -> Drawing\n== Laws ==\n7. above (rot x) (rot y) = rot (beside y x)\n8. beside (rot x) (rot y) = rot (above x y)\n9. over (rot x) (rot y) = rot (over x y)\n10. rot (rot (rot (rot x))) = x\n== Functions ==\nflip :: Drawing -> Drawing\n== Laws ==\n11. flip (flip x) = x\n12. rot (flip (rot x)) = flip x\n13. above (flip x) (flip y) = flip (above x y)\n14. over (flip x) (flip y) = flip (over x y)\n== Functions ==\nrot45 :: Drawing -> Drawing\n== Laws ==\n15. rot45 (flip (rot x)) = flip (rot45 x)\n16. over (rot45 x) (rot45 y) = rot45 (over x y)\n17. rot45 (rot (rot45 (rot (flip x)))) =",
    "rot (flip (rot45 (rot (rot45 x))))\n18. rot (rot (rot45 (rot (rot45 (flip x))))) =\nflip (rot (rot45 (rot (rot45 (rot x)))))\n19. rot (rot (rot45 (rot (rot45 (rot x))))) =\nflip (rot (rot45 (rot (rot45 (flip x)))))\n20. rot45 (rot (rot45 (rot45 (rot (rot x))))) =\nrot (rot45 (rot (rot45 (rot (rot45 x)))))\n21. rot45 (rot45 (rot45 (rot45 (rot (flip x))))) =\nrot (flip (rot45 (rot45 (rot45 (rot45 x)))))\n== Functions ==\nblank :: Drawing\n== Laws ==\n22. flip blank = blank\n23. rot blank = blank\n24. rot45 blank = blank\n25. over x blank = x\n26. above blank blank = blank\n27. above blank (rot45 (rot (rot x))) =\nrot (rot (above blank (rot45 x)))\n28. above (rot45 (rot45 (rot45 x))) blank =\nrot45 (rot45 (beside (rot45 x) blank))\n29. beside (rot45 (rot45 (rot45 x))) blank =\nrot45 (rot45 (above (rot45 x) blank))\n30. rot (rot (rot45 (rot (rot45 x)))) = above blank (beside blank x)\n31. rot (rot45 (rot (rot (rot45 x)))) = above (beside x blank) blank\n32. above blank (rot45 (rot45 (rot (rot x)))) =\nrot (beside blank (rot45 (rot (rot45 x))))\n33. above blank (rot45 (rot45 (rot (rot45 x)))) =\nrot45 (rot (rot45 (above (rot45 x) blank)))\n34. above (rot45 (flip (rot45 (rot45 x)))) blank =\nrot45 (flip (rot45 (above blank (rot45 x))))\n35. above (rot45 (rot (rot45 (rot45 x)))) blank =\nrot45 (rot (rot45 (above blank (rot45 x))))\n36. above (rot45 (rot45 (flip (rot45 x)))) blank =\nrot45 (rot45 (flip (beside blank (rot45 x))))\n37. above (rot45 (rot45 (rot (rot45 x)))) blank =\nrot45 (rot45 (rot (above (rot45 x) blank)))\n38. beside (rot45 (flip (rot45 (rot45 x)))) blank =\nrot45 (flip (rot45 (beside blank (rot45 x))))\n39. beside (rot45 (rot (rot45 (rot45 x)))) blank =\nrot45 (rot (rot45 (beside blank (rot45 x))))\n40. beside (rot45 (rot45 (flip (rot45 x)))) blank =",
    "rot45 (rot45 (flip (above (rot45 x) blank)))\n41. beside (rot45 (rot45 (rot (rot45 x)))) blank =\nrot45 (rot45 (rot (beside blank (rot45 x))))\n42. flip (rot45 (rot (rot45 (rot45 (flip x))))) =\nabove blank (beside blank (rot45 (rot x)))\n43. flip (rot45 (rot (rot45 (rot45 (rot x))))) =\nabove blank (beside blank (rot45 (flip x)))\n44. rot45 (rot (rot45 (flip (rot45 (rot x))))) =\nabove blank (beside (rot45 (flip x)) blank)\n45. rot45 (rot (rot45 (rot45 (rot (flip x))))) =\nflip (above blank (beside blank (rot45 x)))"
  ]
}