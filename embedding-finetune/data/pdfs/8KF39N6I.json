{
  "key": "8KF39N6I",
  "url": "https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf",
  "text": [
    "MapReduce:Simpli\u0002edDataProcessingonLargeClusters\nJeffrey DeanandSanjayGhemawat\njeff@google.com,sanjay@google.com\nGoogle, Inc.\nAbstract\nMapReduceisa programmingmodelandanassoci-\natedimplementationforprocessingandgeneratinglarge\ndatasets.Usersspecifyamapfunctionthatprocessesa\nkey/valuepairto generatea setofintermediatekey/value\npairs,andareducefunctionthatmergesallintermediate\nvaluesassociatedwiththesameintermediatekey. Many\nrealworldtasksareexpressibleinthismodel,asshown\ninthepaper.\nProgramswritteninthisfunctionalstyleareautomati-\ncallyparallelizedandexecutedona largeclusterofcom-\nmoditymachines.Therun-timesystemtakescareofthe\ndetailsofpartitioningtheinputdata,schedulingthepro-\ngram's executionacrossa setofmachines,handlingma-\nchinefailures,andmanagingtherequiredinter-machine\ncommunication.Thisallowsprogrammerswithoutany\nexperiencewithparallelanddistributedsystemstoeas-\nilyutilizetheresourcesofa largedistributedsystem.\nOurimplementationofMapReducerunsona  large\nclusterofcommoditymachinesandishighlyscalable:\na typicalMapReducecomputationprocessesmany ter-\nabytesofdataonthousandsofmachines.Programmers\n\u0002ndthesystemeasyto use:hundredsofMapReducepro-\ngramshave beenimplementedandupwardsofonethou-\nsandMapReducejobsareexecutedonGoogle's clusters\neveryday.\n1Introduction\nOverthepast\u0002ve years,theauthorsandmany othersat\nGooglehave implementedhundredsofspecial-purpose\ncomputationsthatprocesslargeamountsofrawdata,\nsuchascrawleddocuments,webrequestlogs,etc.,to\ncomputevariouskindsofderiveddata,suchasinverted\nindices,variousrepresentationsofthegraphstructure\nofwebdocuments,summariesofthenumberofpages\ncrawledperhost,thesetofmostfrequentqueriesina\ngivenday, etc.Mostsuchcomputationsareconceptu-\nallystraightforward.However, theinputdatais usually\nlargeandthecomputationshave tobedistributedacross\nhundredsorthousandsofmachinesinorderto\u0002nishin\na reasonableamountoftime.Theissuesofhow topar-\nallelizethecomputation,distributethedata,andhandle\nfailuresconspiretoobscuretheoriginalsimplecompu-\ntationwithlargeamountsofcomplex codetodealwith\ntheseissues.\nAsa reactiontothiscomplexity, wedesigneda new\nabstractionthatallowsusto expressthesimplecomputa-\ntionsweweretryingtoperformbuthidesthemessyde-\ntailsofparallelization,fault-tolerance,datadistribution\nandloadbalancingina  library.   Ourabstractionisin-\nspiredbythemapandreduceprimitivespresentinLisp\nandmany otherfunctionallanguages.We realizedthat\nmostofourcomputationsinvolvedapplyingamapop-\nerationtoeachlogicalìrecordîinourinputinorderto\ncomputea setofintermediatekey/valuepairs,andthen\napplyingareduceoperationtoallthevaluesthatshared\nthesamekey, inordertocombinethederiveddataap-\npropriately.   Ouruseofa  functionalmodelwithuser-\nspeci\u0002edmapandreduceoperationsallowsustoparal-\nlelizelargecomputationseasilyandtousere-execution\nastheprimarymechanismforfaulttolerance.\nThemajorcontributionsofthisworkarea simpleand\npowerfulinterfacethatenablesautomaticparallelization\nanddistributionoflarge-scalecomputations,combined\nwithanimplementationofthisinterfacethatachieves\nhighperformanceonlargeclustersofcommodityPCs.\nSection2 describesthebasicprogrammingmodeland\ngivesseveralexamples.Section3 describesanimple-\nmentationoftheMapReduceinterfacetailoredtowards\nourcluster-basedcomputingenvironment.Section4 de-\nscribesseveralre\u0002nementsoftheprogrammingmodel\nthatwehave founduseful.Section5 hasperformance\nmeasurementsofourimplementationfora  varietyof\ntasks.Section6 explorestheuseofMapReducewithin\nGoogleincludingourexperiencesinusingit asthebasis\nTo appearinOSDI20041",
    "fora rewriteofourproductionindexingsystem.Sec-\ntion7 discussesrelatedandfuturework.\n2ProgrammingModel\nThecomputationtakesa setofinputkey/valuepairs,and\nproducesa  setofoutputkey/valuepairs.Theuserof\ntheMapReducelibraryexpressesthecomputationastwo\nfunctions:MapandReduce.\nMap, writtenbytheuser, takesaninputpairandpro-\nducesa setofintermediatekey/valuepairs.TheMapRe-\nducelibrarygroupstogetherallintermediatevaluesasso-\nciatedwiththesameintermediatekeyIandpassesthem\ntotheReducefunction.\nTheReducefunction,alsowrittenbytheuser, accepts\nanintermediatekeyIanda setofvaluesforthatkey. It\nmergestogetherthesevaluestoforma possiblysmaller\nsetofvalues.Typicallyjustzerooroneoutputvalueis\nproducedperReduceinvocation.Theintermediateval-\nuesaresuppliedtotheuser's reducefunctionviaaniter-\nator.  Thisallowsustohandlelistsofvaluesthataretoo\nlargeto\u0002tinmemory.\n2.1Example\nConsidertheproblemofcountingthenumberofoc-\ncurrencesofeachwordina  largecollectionofdocu-\nments.Theuserwouldwritecodesimilartothefollow-\ningpseudo-code:\nmap(Stringkey,Stringvalue):\n// key:documentname\n// value:documentcontents\nforeachwordw in value:\nEmitIntermediate(w,\"1\");\nreduce(Stringkey,Iteratorvalues):\n// key:a word\n// values:a listof counts\nintresult= 0;\nforeachv in values:\nresult+= ParseInt(v);\nEmit(AsString(result));\nThemapfunctionemitseachwordplusanassociated\ncountofoccurrences(just`1'inthissimpleexample).\nThereducefunctionsumstogetherallcountsemitted\nfora particularword.\nInaddition,theuserwritescodeto\u0002llinamapreduce\nspeci\u0002cationobjectwiththenamesoftheinputandout-\nput\u0002les,andoptionaltuningparameters.Theuserthen\ninvokestheMapReducefunction,passingit thespeci\u0002-\ncationobject.Theuser's codeis linkedtogetherwiththe\nMapReducelibrary(implementedinC++).AppendixA\ncontainsthefullprogramtextforthisexample.\n2.2Types\nEventhoughthepreviouspseudo-codeis writtenin terms\nofstringinputsandoutputs,conceptuallythemapand\nreducefunctionssuppliedbytheuserhave  associated\ntypes:\nmap(k1,v1)!list(k2,v2)\nreduce(k2,list(v2))!list(v2)\nI.e.,theinputkeysandvaluesaredrawnfroma different\ndomainthantheoutputkeysandvalues.Furthermore,\ntheintermediatekeysandvaluesarefromthesamedo-\nmainastheoutputkeysandvalues.\nOurC++implementationpassesstringstoandfrom\ntheuser-de\u0002nedfunctionsandleavesit totheusercode\ntoconvertbetweenstringsandappropriatetypes.\n2.3More Examples\nHerearea few simpleexamplesofinterestingprograms\nthatcanbeeasilyexpressedasMapReducecomputa-\ntions.\nDistributedGrep:Themapfunctionemitsa lineif it\nmatchesa suppliedpattern.Thereducefunctionisan\nidentityfunctionthatjustcopiesthesuppliedintermedi-\natedatatotheoutput.\nCountofURLAccessFrequency:Themapfunc-\ntionprocesseslogsofwebpagerequestsandoutputs\nhURL;1i.  Thereducefunctionaddstogetherallvalues\nforthesameURLandemitsahURL;totalcounti\npair.\nReverseWeb-LinkGraph:Themapfunctionoutputs\nhtarget;sourceipairsforeachlinktoatarget\nURLfoundina  pagenamedsource.Thereduce\nfunctionconcatenatesthelistofallsourceURLsas-\nsociatedwitha  giventargetURLandemitsthepair:\nhtarget; list(source)i\nTerm-VectorperHost:A termvectorsummarizesthe\nmostimportantwordsthatoccurina documentora set\nofdocumentsasa listofhword; f requencyipairs.The\nmapfunctionemitsahhostname;termvectori\npairforeachinputdocument(wherethehostnameis\nextractedfromtheURLofthedocument).There-\nducefunctionispassedallper-documenttermvectors\nfora  givenhost.Itaddsthesetermvectorstogether,\nthrowingawayinfrequentterms,andthenemitsa \u0002nal\nhhostname;termvectoripair.\nTo appearinOSDI20042",
    "User\nProgram\nMaster\n(1) fork\nworker\n(1) fork\nworker\n(1) fork\n(2)\nassign\nmap\n(2)\nassign\nreduce\nsplit 0\nsplit 1\nsplit 2\nsplit 3\nsplit 4\n  \noutput\nfile 0\n    \n(6) write\nworker\n(3) read\nworker\n  \n(4) local write\n  \nMap\nphase\nIntermediate files\n(on local disks)\nworker\noutput\nfile 1\nInput\nfiles\n(5) remote read\nReduce\nphase\nOutput\nfiles\nFigure1:Executionoverview\nInvertedIndex:Themapfunctionparseseachdocu-\nment,andemitsa sequenceofhword;documentIDi\npairs.Thereducefunctionacceptsallpairsfora given\nword,sortsthecorrespondingdocumentIDsandemitsa\nhword; list(documentID)ipair. Thesetofalloutput\npairsformsa simpleinvertedindex.It is easyto augment\nthiscomputationtokeeptrackofwordpositions.\nDistributedSort:Themapfunctionextractsthekey\nfromeachrecord,andemitsahkey;recordipair. The\nreducefunctionemitsallpairsunchanged.Thiscompu-\ntationdependsonthepartitioningfacilitiesdescribedin\nSection4.1andtheorderingpropertiesdescribedinSec-\ntion4.2.\n3Implementation\nMany differentimplementationsoftheMapReducein-\nterfacearepossible.Therightchoicedependsonthe\nenvironment.Forexample,oneimplementationmaybe\nsuitablefora smallshared-memorymachine,anotherfor\na largeNUMAmulti-processor, andyetanotherforan\nevenlargercollectionofnetworkedmachines.\nThissectiondescribesanimplementationtargeted\ntothecomputingenvironmentinwideuseatGoogle:\nlargeclustersofcommodityPCsconnectedtogetherwith\nswitchedEthernet[4]. Inourenvironment:\n(1)Machinesaretypicallydual-processorx86processors\nrunningLinux,with2-4GBofmemorypermachine.\n(2)Commoditynetworkinghardwareis usedñ typically\neither100megabits/secondor1  gigabit/secondatthe\nmachinelevel,butaveragingconsiderablylessinover-\nallbisectionbandwidth.\n(3)Aclusterconsistsofhundredsorthousandsofma-\nchines,andthereforemachinefailuresarecommon.\n(4)Storageisprovidedbyinexpensive  IDEdisksat-\ntacheddirectlytoindividualmachines.A distributed\u0002le\nsystem[8] developedin-houseis usedto managethedata\nstoredonthesedisks.The\u0002lesystemusesreplicationto\nprovideavailabilityandreliabilityontopofunreliable\nhardware.\n(5)Userssubmitjobstoa schedulingsystem.Eachjob\nconsistsofa setoftasks,andis mappedbythescheduler\ntoa setofavailablemachineswithina cluster.\n3.1ExecutionOverview\nTheMapinvocationsaredistributedacrossmultiple\nmachinesbyautomaticallypartitioningtheinputdata\nTo appearinOSDI20043",
    "intoa  setofMsplits.Theinputsplitscanbepro-\ncessedinparallelbydifferentmachines.Reduceinvoca-\ntionsaredistributedbypartitioningtheintermediatekey\nspaceintoRpiecesusinga partitioningfunction(e.g.,\nhash(key)modR).Thenumberofpartitions(R) and\nthepartitioningfunctionarespeci\u0002edbytheuser.\nFigure1 showstheoverall\u0003owofa MapReduceop-\nerationinourimplementation.Whentheuserprogram\ncallstheMapReducefunction,thefollowingsequence\nofactionsoccurs(thenumberedlabelsinFigure1 corre-\nspondtothenumbersinthelistbelow):\n1.TheMapReducelibraryintheuserprogram\u0002rst\nsplitstheinput\u0002lesintoMpiecesoftypically16\nmegabytesto64megabytes(MB)perpiece(con-\ntrollablebytheuserviaanoptionalparameter).It\nthenstartsupmany copiesoftheprogramona clus-\nterofmachines.\n2.Oneofthecopiesoftheprogramisspecialñ the\nmaster. Therestareworkersthatareassignedwork\nbythemaster. ThereareMmaptasksandRreduce\ntaskstoassign.Themasterpicksidleworkersand\nassignseachonea maptaskora reducetask.\n3.Aworkerwhoisassigneda  maptaskreadsthe\ncontentsofthecorrespondinginputsplit.It parses\nkey/valuepairsoutoftheinputdataandpasseseach\npairtotheuser-de\u0002nedMapfunction.Theinterme-\ndiatekey/valuepairsproducedbytheMapfunction\narebufferedinmemory.\n4.Periodically, thebufferedpairsarewrittentolocal\ndisk,partitionedintoRregionsbythepartitioning\nfunction.Thelocationsofthesebufferedpairson\nthelocaldiskarepassedbacktothemaster,  who\nis responsibleforforwardingtheselocationstothe\nreduceworkers.\n5.Whena  reduceworkerisnoti\u0002edbythemaster\nabouttheselocations,it usesremoteprocedurecalls\ntoreadthebuffereddatafromthelocaldisksofthe\nmapworkers.Whena reduceworker hasreadallin-\ntermediatedata,it sortsit bytheintermediatekeys\nsothatalloccurrencesofthesamekey aregrouped\ntogether.   Thesortingisneededbecausetypically\nmany differentkeysmaptothesamereducetask.If\ntheamountofintermediatedatais toolargeto\u0002tin\nmemory, anexternalsortis used.\n6.Thereduceworkeriteratesoverthesortedinterme-\ndiatedataandforeachuniqueintermediatekey en-\ncountered,it passesthekey andthecorresponding\nsetofintermediatevaluesto theuser'sReducefunc-\ntion.TheoutputoftheReducefunctionis appended\ntoa \u0002naloutput\u0002leforthisreducepartition.\n7.Whenallmaptasksandreducetaskshave  been\ncompleted,themasterwakesuptheuserprogram.\nAtthispoint,theMapReducecallintheuserpro-\ngramreturnsbacktotheusercode.\nAftersuccessfulcompletion,theoutputofthemapre-\nduceexecutionis availableintheRoutput\u0002les(oneper\nreducetask,with\u0002lenamesasspeci\u0002edbytheuser).\nTypically, usersdonotneedtocombinetheseRoutput\n\u0002lesintoone\u0002leñ they oftenpassthese\u0002lesasinputto\nanotherMapReducecall,orusethemfromanotherdis-\ntributedapplicationthatis abletodealwithinputthatis\npartitionedintomultiple\u0002les.\n3.2MasterDataStructures\nThemasterkeepsseveraldatastructures.Foreachmap\ntaskandreducetask,it storesthestate(idle,in-progress,\norcompleted),  andtheidentityoftheworkermachine\n(fornon-idletasks).\nThemasteris theconduitthroughwhichthelocation\nofintermediate\u0002leregionsis propagatedfrommaptasks\ntoreducetasks.Therefore,foreachcompletedmaptask,\nthemasterstoresthelocationsandsizesoftheRinter-\nmediate\u0002leregionsproducedbythemaptask.Updates\ntothislocationandsizeinformationarereceivedasmap\ntasksarecompleted.Theinformationispushedincre-\nmentallytoworkersthathavein-progressreducetasks.\n3.3FaultTolerance\nSincetheMapReducelibraryis designedtohelpprocess\nverylargeamountsofdatausinghundredsorthousands\nofmachines,thelibrarymusttoleratemachinefailures\ngracefully.\nWorkerFailure\nThemasterpingseveryworkerperiodically.   Ifnore-\nsponseis receivedfroma workerina certainamountof\ntime,themastermarkstheworkerasfailed.Any map\ntaskscompletedbytheworker areresetbacktotheirini-\ntialidlestate,andthereforebecomeeligibleforschedul-\ningonotherworkers.Similarly, any maptaskorreduce\ntaskinprogressona failedworkerisalsoresettoidle\nandbecomeseligibleforrescheduling.\nCompletedmaptasksarere-executedona failurebe-\ncausetheiroutputisstoredonthelocaldisk(s)ofthe\nfailedmachineandis thereforeinaccessible.Completed\nreducetasksdonotneedtobere-executedsincetheir\noutputis storedina global\u0002lesystem.\nWhena maptaskisexecuted\u0002rstbyworkerAand\nthenlaterexecutedbyworkerB(becauseAfailed),all\nTo appearinOSDI20044",
    "workersexecutingreducetasksarenoti\u0002edofthere-\nexecution.Any reducetaskthathasnotalreadyreadthe\ndatafromworkerAwillreadthedatafromworkerB.\nMapReduceis resilienttolarge-scaleworkerfailures.\nForexample,duringoneMapReduceoperation,network\nmaintenanceona runningclusterwascausinggroupsof\n80machinesata timetobecomeunreachableforsev-\neralminutes.TheMapReducemastersimplyre-executed\ntheworkdonebytheunreachableworkermachines,and\ncontinuedto make forwardprogress,eventuallycomplet-\ningtheMapReduceoperation.\nMasterFailure\nIt is easytomake themasterwriteperiodiccheckpoints\nofthemasterdatastructuresdescribedabove. If themas-\ntertaskdies,a  newcopy  canbestartedfromthelast\ncheckpointedstate.However, giventhatthereis onlya\nsinglemaster,  itsfailureisunlikely;thereforeourcur-\nrentimplementationabortstheMapReducecomputation\nif themasterfails.Clientscancheckforthiscondition\nandretrytheMapReduceoperationif they desire.\nSemanticsinthePresenceofFailures\nWhentheuser-suppliedmapandreduceoperatorsarede-\nterministicfunctionsoftheirinputvalues,ourdistributed\nimplementationproducesthesameoutputaswouldhave\nbeenproducedbya non-faultingsequentialexecutionof\ntheentireprogram.\nWe relyonatomiccommitsofmapandreducetask\noutputstoachieve thisproperty.  Eachin-progresstask\nwritesitsoutputto privatetemporary\u0002les.A reducetask\nproducesonesuch\u0002le,anda maptaskproducesRsuch\n\u0002les(oneperreducetask).Whena maptaskcompletes,\ntheworkersendsa messagetothemasterandincludes\nthenamesoftheRtemporary\u0002lesinthemessage.If\nthemasterreceivesa completionmessageforanalready\ncompletedmaptask,it ignoresthemessage.Otherwise,\nit recordsthenamesofR\u0002lesina masterdatastructure.\nWhena  reducetaskcompletes,thereduceworker\natomicallyrenamesitstemporaryoutput\u0002letothe\u0002nal\noutput\u0002le.If thesamereducetaskis executedonmulti-\nplemachines,multiplerenamecallswillbeexecutedfor\nthesame\u0002naloutput\u0002le.We relyontheatomicrename\noperationprovidedbytheunderlying\u0002lesystemto guar-\nanteethatthe\u0002nal\u0002lesystemstatecontainsjustthedata\nproducedbyoneexecutionofthereducetask.\nThevastmajorityofourmapandreduceoperatorsare\ndeterministic,andthefactthatoursemanticsareequiv-\nalenttoa sequentialexecutioninthiscasemakesit very\neasyforprogrammersto reasonabouttheirprogram's be-\nhavior.  Whenthemapand/orreduceoperatorsarenon-\ndeterministic,weprovideweakerbutstillreasonablese-\nmantics.Inthepresenceofnon-deterministicoperators,\ntheoutputofa particularreducetaskR\n1\nis equivalentto\ntheoutputforR\n1\nproducedbya sequentialexecutionof\nthenon-deterministicprogram.However, theoutputfor\na differentreducetaskR\n2\nmaycorrespondtotheoutput\nforR\n2\nproducedbya differentsequentialexecutionof\nthenon-deterministicprogram.\nConsidermaptaskMandreducetasksR\n1\nandR\n2\n.\nLete(R\ni\n)betheexecutionofR\ni\nthatcommitted(there\nisexactlyonesuchexecution).Theweakersemantics\narisebecausee(R\n1\n)mayhave readtheoutputproduced\nbyoneexecutionofMande(R\n2\n)mayhave  readthe\noutputproducedbya differentexecutionofM.\n3.4Locality\nNetworkbandwidthis a relativelyscarceresourceinour\ncomputingenvironment.We  conserve  networkband-\nwidthbytakingadvantageofthefactthattheinputdata\n(managedbyGFS[8]) is storedonthelocaldisksofthe\nmachinesthatmake upourcluster.   GFSdivideseach\n\u0002leinto64MBblocks,andstoresseveralcopiesofeach\nblock(typically3  copies)ondifferentmachines.The\nMapReducemastertakesthelocationinformationofthe\ninput\u0002lesintoaccountandattemptstoschedulea map\ntaskona machinethatcontainsa replicaofthecorre-\nspondinginputdata.Failingthat,it attemptstoschedule\na maptaskneara replicaofthattask's inputdata(e.g.,on\na workermachinethatis onthesamenetworkswitchas\nthemachinecontainingthedata).Whenrunninglarge\nMapReduceoperationsona  signi\u0002cantfractionofthe\nworkersina cluster, mostinputdatais readlocallyand\nconsumesnonetworkbandwidth.\n3.5TaskGranularity\nWe subdividethemapphaseintoMpiecesandthere-\nducephaseintoRpieces,asdescribedabove. Ideally,M\nandRshouldbemuchlargerthanthenumberofworker\nmachines.Havingeachworkerperformmany different\ntasksimprovesdynamicloadbalancing,andalsospeeds\nuprecoverywhena workerfails:themany maptasks\nit hascompletedcanbespreadoutacrossalltheother\nworkermachines.\nTherearepracticalboundsonhow largeMandRcan\nbeinourimplementation,sincethemastermustmake\nO(M+R)schedulingdecisionsandkeepsO(M\u0003R)\nstateinmemoryasdescribedabove.(Theconstantfac-\ntorsformemoryusagearesmallhowever:theO(M\u0003R)\npieceofthestateconsistsofapproximatelyonebyteof\ndatapermaptask/reducetaskpair.)\nTo appearinOSDI20045",
    "Furthermore,Ris oftenconstrainedbyusersbecause\ntheoutputofeachreducetaskendsupina separateout-\nput\u0002le.Inpractice,wetendtochooseMsothateach\nindividualtaskis roughly16MBto64MBofinputdata\n(sothatthelocalityoptimizationdescribedabove is most\neffective),andwemakeRa smallmultipleofthenum-\nberofworkermachinesweexpecttouse.We oftenper-\nformMapReducecomputationswithM= 200;000and\nR= 5;000, using2,000workermachines.\n3.6BackupTasks\nOneofthecommoncausesthatlengthensthetotaltime\ntakenfora MapReduceoperationis a ìstragglerî:a ma-\nchinethattakesanunusuallylongtimetocompleteone\nofthelastfewmaporreducetasksinthecomputation.\nStragglerscanarisefora wholehostofreasons.Forex-\nample,a machinewitha baddiskmayexperiencefre-\nquentcorrectableerrorsthatslowitsreadperformance\nfrom30MB/sto1 MB/s.Theclusterschedulingsys-\ntemmayhave  scheduledothertasksonthemachine,\ncausingit toexecutetheMapReducecodemoreslowly\nduetocompetitionforCPU,memory, localdisk,ornet-\nworkbandwidth.A recentproblemweexperiencedwas\na buginmachineinitializationcodethatcausedproces-\nsorcachestobedisabled:computationsonaffectedma-\nchinessloweddownbyover a factorofonehundred.\nWe have a generalmechanismtoalleviatetheprob-\nlemofstragglers.Whena MapReduceoperationis close\ntocompletion,themasterschedulesbackupexecutions\noftheremainingin-progresstasks.Thetaskis marked\nascompletedwhenevereithertheprimaryorthebackup\nexecutioncompletes.We have tunedthismechanismso\nthatit  typicallyincreasesthecomputationalresources\nusedbytheoperationbynomorethana fewpercent.\nWe  have  foundthatthissigni\u0002cantlyreducesthetime\ntocompletelargeMapReduceoperations.Asanexam-\nple,thesortprogramdescribedinSection5.3takes44%\nlongertocompletewhenthebackuptaskmechanismis\ndisabled.\n4Re\u0002nements\nAlthoughthebasicfunctionalityprovidedbysimply\nwritingMapandReducefunctionsis suf\u0002cientformost\nneeds,wehave founda few extensionsuseful.Theseare\ndescribedinthissection.\n4.1PartitioningFunction\nTheusersofMapReducespecifythenumberofreduce\ntasks/output\u0002lesthatthey desire(R).Datagetsparti-\ntionedacrossthesetasksusinga partitioningfunctionon\ntheintermediatekey.  Adefaultpartitioningfunctionis\nprovidedthatuseshashing(e.g.ìhash(key)modRî).\nThistendstoresultinfairlywell-balancedpartitions.In\nsomecases,however,  it  isusefultopartitiondataby\nsomeotherfunctionofthekey. Forexample,sometimes\ntheoutputkeysareURLs,andwewantallentriesfora\nsinglehosttoendupinthesameoutput\u0002le.To support\nsituationslike  this,theuseroftheMapReducelibrary\ncanprovidea specialpartitioningfunction.Forexample,\nusingìhash(Hostname(urlkey))modRî asthepar-\ntitioningfunctioncausesallURLsfromthesamehostto\nendupinthesameoutput\u0002le.\n4.2OrderingGuarantees\nWe guaranteethatwithina givenpartition,theinterme-\ndiatekey/valuepairsareprocessedinincreasingkey or-\nder.  Thisorderingguaranteemakesit easytogenerate\na sortedoutput\u0002leperpartition,whichisusefulwhen\ntheoutput\u0002leformatneedstosupportef\u0002cientrandom\naccesslookupsbykey, orusersoftheoutput\u0002ndit con-\nvenienttohave thedatasorted.\n4.3CombinerFunction\nInsomecases,thereis signi\u0002cantrepetitionintheinter-\nmediatekeysproducedbyeachmaptask,andtheuser-\nspeci\u0002edReducefunctioniscommutative andassocia-\ntive. A goodexampleofthisis thewordcountingexam-\npleinSection2.1.Sincewordfrequenciestendto follow\na Zipfdistribution,eachmaptaskwillproducehundreds\northousandsofrecordsoftheform<the,1>.  Allof\nthesecountswillbesentoverthenetworktoa singlere-\nducetaskandthenaddedtogetherbytheReducefunction\ntoproduceonenumber. We allow theusertospecifyan\noptionalCombinerfunctionthatdoespartialmergingof\nthisdatabeforeit is sentoverthenetwork.\nTheCombinerfunctionis executedoneachmachine\nthatperformsa maptask.Typicallythesamecodeis used\ntoimplementboththecombinerandthereducefunc-\ntions.Theonlydifferencebetweena reducefunctionand\na combinerfunctionis how theMapReducelibraryhan-\ndlestheoutputofthefunction.Theoutputofa reduce\nfunctionis writtentothe\u0002naloutput\u0002le.Theoutputof\na combinerfunctionis writtentoanintermediate\u0002lethat\nwillbesenttoa reducetask.\nPartialcombiningsigni\u0002cantlyspeedsupcertain\nclassesofMapReduceoperations.AppendixA contains\nanexamplethatusesa combiner.\n4.4InputandOutputTypes\nTheMapReducelibraryprovidessupportforreadingin-\nputdatainseveraldifferentformats.Forexample,ìtextî\nTo appearinOSDI20046",
    "modeinputtreatseachlineasa key/valuepair:thekey\nistheoffsetinthe\u0002leandthevalueisthecontentsof\ntheline.Anothercommonsupportedformatstoresa\nsequenceofkey/valuepairssortedbykey.   Eachinput\ntypeimplementationknowshow to splititselfintomean-\ningfulrangesforprocessingasseparatemaptasks(e.g.\ntextmode's rangesplittingensuresthatrangesplitsoc-\ncuronlyat lineboundaries).Userscanaddsupportfora\nnew inputtypebyprovidinganimplementationofa sim-\nplereaderinterface,thoughmostusersjustuseoneofa\nsmallnumberofprede\u0002nedinputtypes.\nAreaderdoesnotnecessarilyneedtoprovidedata\nreadfroma \u0002le.Forexample,it is easyto de\u0002neareader\nthatreadsrecordsfroma database,orfromdatastruc-\nturesmappedinmemory.\nIna similarfashion,wesupporta setofoutputtypes\nforproducingdataindifferentformatsandit is easyfor\nusercodetoaddsupportfornew outputtypes.\n4.5Side-effects\nInsomecases,usersofMapReducehave foundit con-\nvenienttoproduceauxiliary\u0002lesasadditionaloutputs\nfromtheirmapand/orreduceoperators.We relyonthe\napplicationwritertomake suchside-effectsatomicand\nidempotent.Typicallytheapplicationwritestoa tempo-\nrary\u0002leandatomicallyrenamesthis\u0002leonceit hasbeen\nfullygenerated.\nWe donotprovidesupportforatomictwo-phasecom-\nmitsofmultipleoutput\u0002lesproducedbya singletask.\nTherefore,tasksthatproducemultipleoutput\u0002leswith\ncross-\u0002leconsistency requirementsshouldbedetermin-\nistic.Thisrestrictionhasnever beenanissueinpractice.\n4.6SkippingBadRecords\nSometimestherearebugsin usercodethatcausetheMap\norReducefunctionstocrashdeterministicallyoncertain\nrecords.Suchbugspreventa MapReduceoperationfrom\ncompleting.Theusualcourseofactionis to\u0002xthebug,\nbutsometimesthisis notfeasible;perhapsthebugis in\na  third-partylibraryforwhichsourcecodeisunavail-\nable.Also,sometimesit isacceptabletoignorea few\nrecords,forexamplewhendoingstatisticalanalysison\na largedataset.We provideanoptionalmodeofexecu-\ntionwheretheMapReducelibrarydetectswhichrecords\ncausedeterministiccrashesandskipstheserecordsin or-\ndertomake forwardprogress.\nEachworkerprocessinstallsa  signalhandlerthat\ncatchessegmentationviolationsandbuserrors.Before\ninvokinga userMaporReduceoperation,theMapRe-\nducelibrarystoresthesequencenumberoftheargument\nina globalvariable.If theusercodegeneratesa signal,\nthesignalhandlersendsa ìlastgaspîUDPpacketthat\ncontainsthesequencenumbertotheMapReducemas-\nter.  Whenthemasterhasseenmorethanonefailureon\na particularrecord,it indicatesthattherecordshouldbe\nskippedwhenit issuesthenext re-executionofthecorre-\nspondingMaporReducetask.\n4.7LocalExecution\nDebuggingproblemsinMaporReducefunctionscanbe\ntricky,  sincetheactualcomputationhappensina  dis-\ntributedsystem,oftenonseveralthousandmachines,\nwithworkassignmentdecisionsmadedynamicallyby\nthemaster.  To helpfacilitatedebugging,pro\u0002ling,and\nsmall-scaletesting,wehave developedanalternative im-\nplementationoftheMapReducelibrarythatsequentially\nexecutesalloftheworkfora MapReduceoperationon\nthelocalmachine.Controlsareprovidedtotheuserso\nthatthecomputationcanbelimitedtoparticularmap\ntasks.Usersinvoke theirprogramwitha special\u0003agand\ncantheneasilyuseany debuggingortestingtoolsthey\n\u0002nduseful(e.g.gdb).\n4.8StatusInformation\nThemasterrunsaninternalHTTPserverandexports\na setofstatuspagesforhumanconsumption.Thesta-\ntuspagesshow theprogressofthecomputation,suchas\nhow many taskshave beencompleted,how many arein\nprogress,bytesofinput,bytesofintermediatedata,bytes\nofoutput,processingrates,etc.Thepagesalsocontain\nlinkstothestandarderrorandstandardoutput\u0002lesgen-\neratedbyeachtask.Theusercanusethisdatatopre-\ndicthow longthecomputationwilltake, andwhetheror\nnotmoreresourcesshouldbeaddedtothecomputation.\nThesepagescanalsobeusedto \u0002gureoutwhenthecom-\nputationis muchslowerthanexpected.\nInaddition,thetop-levelstatuspageshowswhich\nworkershave  failed,andwhichmapandreducetasks\nthey wereprocessingwhenthey failed.Thisinforma-\ntionisusefulwhenattemptingtodiagnosebugsinthe\nusercode.\n4.9Counters\nTheMapReducelibraryprovidesa  counterfacilityto\ncountoccurrencesofvariousevents.Forexample,user\ncodemaywantto counttotalnumberofwordsprocessed\northenumberofGermandocumentsindexed,etc.\nTo usethisfacility, usercodecreatesa namedcounter\nobjectandthenincrementsthecounterappropriatelyin\ntheMapand/orReducefunction.Forexample:\nTo appearinOSDI20047",
    "Counter*uppercase;\nuppercase= GetCounter(\"uppercase\");\nmap(Stringname,Stringcontents):\nforeachwordw in contents:\nif (IsCapitalized(w)):\nuppercase->Increment();\nEmitIntermediate(w,\"1\");\nThecountervaluesfromindividualworkermachines\nareperiodicallypropagatedtothemaster(piggybacked\nonthepingresponse).Themasteraggregatesthecounter\nvaluesfromsuccessfulmapandreducetasksandreturns\nthemtotheusercodewhentheMapReduceoperation\niscompleted.Thecurrentcountervaluesarealsodis-\nplayedonthemasterstatuspagesothata  humancan\nwatchtheprogressofthelive computation.Whenaggre-\ngatingcountervalues,themastereliminatestheeffectsof\nduplicateexecutionsofthesamemaporreducetaskto\navoiddoublecounting.(Duplicateexecutionscanarise\nfromouruseofbackuptasksandfromre-executionof\ntasksduetofailures.)\nSomecountervaluesareautomaticallymaintained\nbytheMapReducelibrary,  suchasthenumberofin-\nputkey/valuepairsprocessedandthenumberofoutput\nkey/valuepairsproduced.\nUsershave foundthecounterfacilityusefulforsan-\nitycheckingthebehaviorofMapReduceoperations.For\nexample,insomeMapReduceoperations,theusercode\nmaywanttoensurethatthenumberofoutputpairs\nproducedexactlyequalsthenumberofinputpairspro-\ncessed,orthatthefractionofGermandocumentspro-\ncessedis withinsometolerablefractionofthetotalnum-\nberofdocumentsprocessed.\n5Performance\nInthissectionwemeasuretheperformanceofMapRe-\nduceontwo computationsrunningona largeclusterof\nmachines.Onecomputationsearchesthroughapproxi-\nmatelyoneterabyteofdatalookingfora particularpat-\ntern.Theothercomputationsortsapproximatelyoneter-\nabyteofdata.\nThesetwo programsarerepresentative ofa largesub-\nsetoftherealprogramswrittenbyusersofMapReduceñ\noneclassofprogramsshuf\u0003esdatafromonerepresenta-\ntionto another, andanotherclassextractsa smallamount\nofinterestingdatafroma largedataset.\n5.1ClusterCon\u0002guration\nAlloftheprogramswereexecutedona  clusterthat\nconsistedofapproximately1800machines.Eachma-\nchinehadtwo 2GHzIntelXeonprocessorswithHyper-\nThreadingenabled,4GBofmemory,  two  160GBIDE\n20406080100\nSeconds\n0\n10000\n20000\n30000\nInput (MB/s)\nFigure2:Datatransferrateovertime\ndisks,anda gigabitEthernetlink.Themachineswere\narrangedina  two-leveltree-shapedswitchednetwork\nwithapproximately100-200Gbpsofaggregateband-\nwidthavailableattheroot.Allofthemachineswere\ninthesamehostingfacilityandthereforetheround-trip\ntimebetweenany pairofmachineswaslessthana mil-\nlisecond.\nOutofthe4GBofmemory, approximately1-1.5GB\nwasreservedbyothertasksrunningonthecluster.  The\nprogramswereexecutedona weekendafternoon,when\ntheCPUs,disks,andnetworkweremostlyidle.\n5.2Grep\nThegrepprogramscansthrough10\n10\n100-byterecords,\nsearchingfora relativelyrarethree-characterpattern(the\npatternoccursin92,337records).Theinputis splitinto\napproximately64MBpieces(M= 15000), andtheen-\ntireoutputis placedinone\u0002le(R= 1).\nFigure2 showstheprogressofthecomputationover\ntime.TheY-axisshowstherateat whichtheinputdatais\nscanned.Therategraduallypicksupasmoremachines\nareassignedtothisMapReducecomputation,andpeaks\nat over30GB/swhen1764workershave beenassigned.\nAsthemaptasks\u0002nish,theratestartsdroppingandhits\nzeroabout80secondsintothecomputation.Theentire\ncomputationtakesapproximately150secondsfromstart\nto\u0002nish.Thisincludesabouta minuteofstartupover-\nhead.Theoverheadis duetothepropagationofthepro-\ngramtoallworker machines,anddelaysinteractingwith\nGFStoopenthesetof1000input\u0002lesandtogetthe\ninformationneededforthelocalityoptimization.\n5.3Sort\nThesortprogramsorts10\n10\n100-byterecords(approxi-\nmately1 terabyteofdata).Thisprogramis modeledafter\ntheTeraSortbenchmark[10].\nThesortingprogramconsistsoflessthan50linesof\nusercode.Athree-lineMapfunctionextractsa 10-byte\nsortingkey froma textlineandemitsthekey andthe\nTo appearinOSDI20048",
    "5001000\n0\n5000\n10000\n15000\n20000\nInput (MB/s)\n5001000\n0\n5000\n10000\n15000\n20000\nShuffle (MB/s)\n5001000\nSeconds\n0\n5000\n10000\n15000\n20000\nOutput (MB/s)\nDone\n(a)Normalexecution\n5001000\n0\n5000\n10000\n15000\n20000\nInput (MB/s)\n5001000\n0\n5000\n10000\n15000\n20000\nShuffle (MB/s)\n5001000\nSeconds\n0\n5000\n10000\n15000\n20000\nOutput (MB/s)\nDone\n(b)Nobackuptasks\n5001000\n0\n5000\n10000\n15000\n20000\nInput (MB/s)\n5001000\n0\n5000\n10000\n15000\n20000\nShuffle (MB/s)\n5001000\nSeconds\n0\n5000\n10000\n15000\n20000\nOutput (MB/s)\nDone\n(c)200taskskilled\nFigure3:Datatransferratesovertimefordifferentexecutionsofthesortprogram\noriginaltextlineastheintermediatekey/valuepair.  We\nuseda built-inIdentityfunctionastheReduceoperator.\nThisfunctionspassestheintermediatekey/valuepairun-\nchangedastheoutputkey/valuepair.   The\u0002nalsorted\noutputiswrittentoa setof2-wayreplicatedGFS\u0002les\n(i.e.,2 terabytesarewrittenastheoutputoftheprogram).\nAsbefore,theinputdataissplitinto64MBpieces\n(M= 15000).  We partitionthesortedoutputinto4000\n\u0002les(R= 4000). Thepartitioningfunctionusestheini-\ntialbytesofthekey tosegregateit intooneofRpieces.\nOurpartitioningfunctionforthisbenchmarkhasbuilt-\ninknowledgeofthedistributionofkeys.Ina general\nsortingprogram,wewouldadda pre-passMapReduce\noperationthatwouldcollecta  sampleofthekeysand\nusethedistributionofthesampledkeysto computesplit-\npointsforthe\u0002nalsortingpass.\nFigure3 (a)showstheprogressofa normalexecution\nofthesortprogram.Thetop-leftgraphshowstherate\natwhichinputis read.Theratepeaksatabout13GB/s\nanddiesoff fairlyquicklysinceallmaptasks\u0002nishbe-\nfore200secondshave elapsed.Notethattheinputrate\nis lessthanforgrep.  Thisis becausethesortmaptasks\nspendabouthalftheirtimeandI/Obandwidthwritingin-\ntermediateoutputtotheirlocaldisks.Thecorresponding\nintermediateoutputforgrephadnegligiblesize.\nThemiddle-leftgraphshowstherateatwhichdata\nissentoverthenetworkfromthemaptaskstothere-\nducetasks.Thisshuf\u0003ingstartsassoonasthe\u0002rst\nmaptaskcompletes.The\u0002rsthumpinthegraphis for\nthe\u0002rstbatchofapproximately1700reducetasks(the\nentireMapReducewasassignedabout1700machines,\nandeachmachineexecutesatmostonereducetaskata\ntime).Roughly300secondsintothecomputation,some\nofthese\u0002rstbatchofreducetasks\u0002nishandwestart\nshuf\u0003ingdatafortheremainingreducetasks.Allofthe\nshuf\u0003ingis doneabout600secondsintothecomputation.\nThebottom-leftgraphshowstherateatwhichsorted\ndatais writtento the\u0002naloutput\u0002lesbythereducetasks.\nThereis a delaybetweentheendofthe\u0002rstshuf\u0003ingpe-\nriodandthestartofthewritingperiodbecausethema-\nchinesarebusysortingtheintermediatedata.Thewrites\ncontinueata rateofabout2-4GB/sfora while.Allof\nthewrites\u0002nishabout850secondsintothecomputation.\nIncludingstartupoverhead,theentirecomputationtakes\n891seconds.Thisis similartothecurrentbestreported\nresultof1057secondsfortheTeraSortbenchmark[18].\nAfew thingstonote:theinputrateis higherthanthe\nshuf\u0003erateandtheoutputratebecauseofourlocality\noptimizationñ mostdataisreadfroma localdiskand\nbypassesourrelativelybandwidthconstrainednetwork.\nTheshuf\u0003erateishigherthantheoutputratebecause\ntheoutputphasewritestwo copiesofthesorteddata(we\nmake two replicasoftheoutputforreliabilityandavail-\nabilityreasons).We writetwo replicasbecausethatis\nthemechanismforreliabilityandavailabilityprovided\nbyourunderlying\u0002lesystem.Networkbandwidthre-\nquirementsforwritingdatawouldbereducedif theun-\nderlying\u0002lesystemusederasurecoding[14] ratherthan\nreplication.\nTo appearinOSDI20049",
    "5.4EffectofBackupTasks\nInFigure3 (b),weshowanexecutionofthesortpro-\ngramwithbackuptasksdisabled.Theexecution\u0003owis\nsimilartothatshowninFigure3 (a),exceptthatthereis\na verylongtailwherehardlyany writeactivityoccurs.\nAfter960seconds,allexcept5 ofthereducetasksare\ncompleted.Howevertheselastfewstragglersdon't \u0002n-\nishuntil300secondslater. Theentirecomputationtakes\n1283seconds,anincreaseof44%inelapsedtime.\n5.5MachineFailures\nInFigure3 (c),weshow anexecutionofthesortprogram\nwhereweintentionallykilled200outof1746worker\nprocessesseveralminutesintothecomputation.The\nunderlyingclusterschedulerimmediatelyrestartednew\nworkerprocessesonthesemachines(sinceonlythepro-\ncesseswerekilled,themachineswerestillfunctioning\nproperly).\nTheworkerdeathsshowupasa  negative inputrate\nsincesomepreviouslycompletedmapworkdisappears\n(sincethecorrespondingmapworkerswerekilled)and\nneedstoberedone.There-executionofthismapwork\nhappensrelativelyquickly.  Theentirecomputation\u0002n-\nishesin933secondsincludingstartupoverhead(justan\nincreaseof5%overthenormalexecutiontime).\n6Experience\nWe wrotethe\u0002rstversionoftheMapReducelibraryin\nFebruaryof2003,andmadesigni\u0002cantenhancementsto\nit inAugustof2003,includingthelocalityoptimization,\ndynamicloadbalancingoftaskexecutionacrossworker\nmachines,etc.Sincethattime,wehave beenpleasantly\nsurprisedathowbroadlyapplicabletheMapReduceli-\nbraryhasbeenforthekindsofproblemsweworkon.\nIt hasbeenusedacrossa widerangeofdomainswithin\nGoogle,including:\n\u000flarge-scalemachinelearningproblems,\n\u000fclusteringproblemsfortheGoogleNewsand\nFroogleproducts,\n\u000fextractionofdatausedto producereportsofpopular\nqueries(e.g.GoogleZeitgeist),\n\u000fextractionofpropertiesofwebpagesfornew exper-\nimentsandproducts(e.g.extractionofgeographi-\ncallocationsfroma largecorpusofwebpagesfor\nlocalizedsearch),and\n\u000flarge-scalegraphcomputations.\n2003/032003/062003/092003/122004/032004/062004/09\n0\n200\n400\n600\n800\n1000\nNumber of instances in source tree\nFigure4:MapReduceinstancesovertime\nNumberofjobs29,423\nAveragejobcompletiontime634secs\nMachinedaysused79,186days\nInputdataread3,288TB\nIntermediatedataproduced758TB\nOutputdatawritten193TB\nAverageworkermachinesperjob157\nAverageworkerdeathsperjob1.2\nAveragemaptasksperjob3,351\nAveragereducetasksperjob55\nUniquemapimplementations395\nUniquereduceimplementations269\nUniquemap/reducecombinations426\nTable1:MapReducejobsruninAugust2004\nFigure4 showsthesigni\u0002cantgrowthinthenumberof\nseparateMapReduceprogramscheckedintoourprimary\nsourcecodemanagementsystemovertime,from0  in\nearly2003toalmost900separateinstancesasoflate\nSeptember2004.MapReducehasbeensosuccessfulbe-\ncauseit makesit possibletowritea simpleprogramand\nrunit ef\u0002cientlyona thousandmachinesinthecourse\nofhalfanhour, greatlyspeedingupthedevelopmentand\nprototypingcycle.Furthermore,it allowsprogrammers\nwhohave noexperiencewithdistributedand/orparallel\nsystemstoexploitlargeamountsofresourceseasily.\nAttheendofeachjob,theMapReducelibrarylogs\nstatisticsaboutthecomputationalresourcesusedbythe\njob.  InTable1,weshowsomestatisticsfora subsetof\nMapReducejobsrunat GoogleinAugust2004.\n6.1Large-ScaleIndexing\nOneofourmostsigni\u0002cantusesofMapReducetodate\nhasbeena  completerewriteoftheproductionindex-\nTo appearinOSDI200410",
    "ingsystemthatproducesthedatastructuresusedforthe\nGooglewebsearchservice.Theindexingsystemtakes\nasinputa largesetofdocumentsthathave beenretrieved\nbyourcrawlingsystem,storedasa setofGFS\u0002les.The\nrawcontentsforthesedocumentsaremorethan20ter-\nabytesofdata.Theindexingprocessrunsasa sequence\nof\u0002ve totenMapReduceoperations.UsingMapReduce\n(insteadofthead-hocdistributedpassesinthepriorver-\nsionoftheindexingsystem)hasprovidedseveralbene-\n\u0002ts:\n\u000fTheindexingcodeis simpler, smaller, andeasierto\nunderstand,becausethecodethatdealswithfault\ntolerance,distributionandparallelizationis hidden\nwithintheMapReducelibrary.Forexample,the\nsizeofonephaseofthecomputationdroppedfrom\napproximately3800linesofC++codetoapprox-\nimately700lineswhenexpressedusingMapRe-\nduce.\n\u000fTheperformanceoftheMapReducelibraryis good\nenoughthatwecankeepconceptuallyunrelated\ncomputationsseparate,insteadofmixingthemto-\ngethertoavoidextrapassesoverthedata.This\nmakesit easytochangetheindexingprocess.For\nexample,onechangethattooka  fewmonthsto\nmake inouroldindexingsystemtookonlya few\ndaystoimplementinthenew system.\n\u000fTheindexingprocesshasbecomemucheasierto\noperate,becausemostoftheproblemscausedby\nmachinefailures,slowmachines,andnetworking\nhiccupsaredealtwithautomaticallybytheMapRe-\nducelibrarywithoutoperatorintervention.Further-\nmore,it is easytoimprove theperformanceofthe\nindexingprocessbyaddingnew machinestothein-\ndexingcluster.\n7RelatedWork\nMany  systemshave  providedrestrictedprogramming\nmodelsandusedtherestrictionstoparallelizethecom-\nputationautomatically. Forexample,anassociative func-\ntioncanbecomputedoverallpre\u0002xesofanNelement\narrayinlogNtimeonNprocessorsusingparallelpre\u0002x\ncomputations[6, 9, 13].MapReducecanbeconsidered\na simpli\u0002cationanddistillationofsomeofthesemodels\nbasedonourexperiencewithlargereal-worldcompu-\ntations.Moresigni\u0002cantly, weprovidea fault-tolerant\nimplementationthatscalestothousandsofprocessors.\nIncontrast,mostoftheparallelprocessingsystemshave\nonlybeenimplementedonsmallerscalesandleave the\ndetailsofhandlingmachinefailurestotheprogrammer.\nBulkSynchronousProgramming[17] andsomeMPI\nprimitives[11]  providehigher-levelabstractionsthat\nmake  it  easierforprogrammerstowriteparallelpro-\ngrams.Akey  differencebetweenthesesystemsand\nMapReduceis thatMapReduceexploitsa restrictedpro-\ngrammingmodeltoparallelizetheuserprogramauto-\nmaticallyandtoprovidetransparentfault-tolerance.\nOurlocalityoptimizationdrawsitsinspirationfrom\ntechniquessuchasactive disks[12, 15], wherecompu-\ntationis pushedintoprocessingelementsthatareclose\ntolocaldisks,toreducetheamountofdatasentacross\nI/Osubsystemsorthenetwork.We runoncommodity\nprocessorstowhicha smallnumberofdisksaredirectly\nconnectedinsteadofrunningdirectlyondiskcontroller\nprocessors,butthegeneralapproachis similar.\nOurbackuptaskmechanismissimilartotheeager\nschedulingmechanismemployedintheCharlotteSys-\ntem[3].Oneoftheshortcomingsofsimpleeager\nschedulingis thatif a giventaskcausesrepeatedfailures,\ntheentirecomputationfailsto complete.We \u0002xsomein-\nstancesofthisproblemwithourmechanismforskipping\nbadrecords.\nTheMapReduceimplementationreliesonanin-house\nclustermanagementsystemthatisresponsiblefordis-\ntributingandrunningusertasksona largecollectionof\nsharedmachines.Thoughnotthefocusofthispaper, the\nclustermanagementsystemissimilarinspirittoother\nsystemssuchasCondor[16].\nThesortingfacilitythatisa partoftheMapReduce\nlibraryis similarinoperationtoNOW-Sort[1].Source\nmachines(mapworkers)partitionthedatatobesorted\nandsendit tooneofRreduceworkers.Eachreduce\nworkersortsitsdatalocally(inmemoryif possible).Of\ncourseNOW-Sortdoesnothave theuser-de\u0002nableMap\nandReducefunctionsthatmake ourlibrarywidelyappli-\ncable.\nRiver[2] providesa programmingmodelwherepro-\ncessescommunicatewitheachotherbysendingdata\noverdistributedqueues.Like  MapReduce,theRiver\nsystemtriestoprovidegoodaveragecaseperformance\neveninthepresenceofnon-uniformitiesintroducedby\nheterogeneoushardwareorsystemperturbations.River\nachievesthisbycarefulschedulingofdiskandnetwork\ntransferstoachieve balancedcompletiontimes.MapRe-\nducehasa  differentapproach.Byrestrictingthepro-\ngrammingmodel,theMapReduceframeworkisable\ntopartitiontheproblemintoa  largenumberof\u0002ne-\ngrainedtasks.Thesetasksaredynamicallyscheduled\nonavailableworkerssothatfasterworkersprocessmore\ntasks.Therestrictedprogrammingmodelalsoallows\nustoscheduleredundantexecutionsoftasksnearthe\nendofthejobwhichgreatlyreducescompletiontimein\nthepresenceofnon-uniformities(suchassloworstuck\nworkers).\nBAD-FS[5] hasa verydifferentprogrammingmodel\nfromMapReduce,andunlike MapReduce,is targetedto\nTo appearinOSDI200411",
    "theexecutionofjobsacrossa wide-areanetwork.How-\never,  therearetwo  fundamentalsimilarities.(1)Both\nsystemsuseredundantexecutiontorecoverfromdata\nlosscausedbyfailures.(2)Bothuselocality-aware\nschedulingtoreducetheamountofdatasentacrosscon-\ngestednetworklinks.\nTACC[7]  isasystemdesignedtosimplifycon-\nstructionofhighly-availablenetworkedservices.Like\nMapReduce,it reliesonre-executionasa mechanismfor\nimplementingfault-tolerance.\n8Conclusions\nTheMapReduceprogrammingmodelhasbeensuccess-\nfullyusedatGoogleformany differentpurposes.We\nattributethissuccesstoseveralreasons.First,themodel\nis easytouse,evenforprogrammerswithoutexperience\nwithparallelanddistributedsystems,sinceit hidesthe\ndetailsofparallelization,fault-tolerance,localityopti-\nmization,andloadbalancing.Second,a  largevariety\nofproblemsareeasilyexpressibleasMapReducecom-\nputations.Forexample,MapReduceis usedforthegen-\nerationofdataforGoogle's productionwebsearchser-\nvice,forsorting,fordatamining,formachinelearning,\nandmany othersystems.Third,wehave developedan\nimplementationofMapReducethatscalestolargeclus-\ntersofmachinescomprisingthousandsofmachines.The\nimplementationmakesef\u0002cientuseofthesemachinere-\nsourcesandthereforeis suitableforuseonmany ofthe\nlargecomputationalproblemsencounteredat Google.\nWe have learnedseveralthingsfromthiswork.First,\nrestrictingtheprogrammingmodelmakesit easytopar-\nallelizeanddistributecomputationsandtomake  such\ncomputationsfault-tolerant.Second,networkbandwidth\nis a scarceresource.Anumberofoptimizationsinour\nsystemarethereforetargetedatreducingtheamountof\ndatasentacrossthenetwork:thelocalityoptimizational-\nlowsusto readdatafromlocaldisks,andwritinga single\ncopy oftheintermediatedatatolocaldisksavesnetwork\nbandwidth.Third,redundantexecutioncanbeusedto\nreducetheimpactofslowmachines,andtohandlema-\nchinefailuresanddataloss.\nAcknowledgements\nJoshLevenberg hasbeeninstrumentalinrevisingand\nextendingtheuser-levelMapReduceAPIwitha  num-\nberofnewfeaturesbasedonhisexperiencewithusing\nMapReduceandotherpeople's suggestionsforenhance-\nments.MapReducereadsitsinputfromandwritesits\noutputtotheGoogleFileSystem[8].We wouldlike to\nthankMohitAron,HowardGobioff, MarkusGutschke,\nDavidKramer, Shun-TakLeung,andJoshRedstonefor\ntheirworkindevelopingGFS.We  wouldalsolike  to\nthankPercy LiangandOlcanSercinoglufortheirwork\nindevelopingtheclustermanagementsystemusedby\nMapReduce.Mike Burrows,WilsonHsieh,JoshLeven-\nberg,SharonPerl,RobPike,andDebbyWallachpro-\nvidedhelpfulcommentsonearlierdraftsofthispa-\nper. TheanonymousOSDIreviewers,andourshepherd,\nEricBrewer, providedmany usefulsuggestionsofareas\nwherethepapercouldbeimproved.Finally, wethankall\ntheusersofMapReducewithinGoogle's engineeringor-\nganizationforprovidinghelpfulfeedback,suggestions,\nandbugreports.\nReferences\n[1]AndreaC.Arpaci-Dusseau,RemziH.Arpaci-Dusseau,\nDavidE.Culler, JosephM.Hellerstein,andDavidA.Pat-\nterson.High-performancesortingonnetworksofwork-\nstations.InProceedingsofthe1997ACMSIGMODIn-\nternationalConferenceonManagementofData, Tucson,\nArizona,May1997.\n[2]RemziH.Arpaci-Dusseau,EricAnderson,Noah\nTreuhaft,DavidE.Culler, JosephM.Hellerstein,David\nPatterson,andKathyYelick.ClusterI/OwithRiver:\nMakingthefastcasecommon.InProceedingsof theSixth\nWorkshoponInput/OutputinParallelandDistributed\nSystems(IOPADS'99),  pages10ñ22,Atlanta,Georgia,\nMay1999.\n[3]ArashBaratloo,MehmetKaraul,ZviKedem,andPeter\nWyckoff.  Charlotte:Metacomputingontheweb.  InPro-\nceedingsofthe9thInternationalConferenceonParallel\nandDistributedComputingSystems, 1996.\n[4]LuizA.Barroso,Jeffrey  Dean,andUrsH ®olzle.Web\nsearchfora planet:TheGoogleclusterarchitecture.IEEE\nMicro, 23(2):22ñ28,April2003.\n[5]JohnBent,DouglasThain,AndreaC.Arpaci-Dusseau,\nRemziH.Arpaci-Dusseau,andMironLivny.Explicit\ncontrolina batch-awaredistributed\u0002lesystem.InPro-\nceedingsofthe1stUSENIXSymposiumonNetworked\nSystemsDesignandImplementationNSDI, March2004.\n[6]GuyE.Blelloch.Scansasprimitive paralleloperations.\nIEEETransactionsonComputers,  C-38(11),November\n1989.\n[7]ArmandoFox,StevenD.Gribble,YatinChawathe,\nEricA.Brewer, andPaulGauthier.   Cluster-basedscal-\nablenetworkservices.InProceedingsofthe16thACM\nSymposiumonOperatingSystemPrinciples,  pages78ñ\n91,Saint-Malo,France,1997.\n[8]SanjayGhemawat,HowardGobioff,  andShun-TakLe-\nung.TheGoogle\u0002lesystem.In19thSymposiumonOp-\neratingSystemsPrinciples,  pages29ñ43,Lake  George,\nNew York,2003.\nTo appearinOSDI200412",
    "[9]S.Gorlatch.Systematicef\u0002cientparallelizationofscan\nandotherlisthomomorphisms.InL.Bouge,P. Fraigni-\naud,A.Mignotte,andY. Robert,editors,Euro-Par'96.\nParallelProcessing, LectureNotesinComputerScience\n1124,pages401ñ408.Springer-Verlag,1996.\n[10]JimGray.Sortbenchmarkhomepage.\nhttp://research.microsoft.com/barc/SortBenchmark/.\n[11]WilliamGropp,EwingLusk,andAnthonySkjellum.\nUsingMPI:PortableParallelProgrammingwiththe\nMessage-PassingInterface. MITPress,Cambridge,MA,\n1999.\n[12]L.Huston,R.Sukthankar, R.Wickremesinghe,M.Satya-\nnarayanan,G.R.Ganger, E.Riedel,andA.Ailamaki.Di-\namond:Astoragearchitectureforearlydiscardininter-\nactive search.InProceedingsofthe2004USENIXFile\nandStorage TechnologiesFASTConference, April2004.\n[13]RichardE.LadnerandMichaelJ. Fischer. Parallelpre\u0002x\ncomputation.JournaloftheACM, 27(4):831ñ838,1980.\n[14]MichaelO.Rabin.Ef\u0002cientdispersalofinformationfor\nsecurity,  loadbalancingandfaulttolerance.Journalof\ntheACM, 36(2):335ñ348,1989.\n[15]ErikRiedel,ChristosFaloutsos,GarthA.Gibson,and\nDavidNagle.Active disksforlarge-scaledataprocess-\ning.IEEEComputer, pages68ñ74,June2001.\n[16]DouglasThain,ToddTannenbaum,andMironLivny.\nDistributedcomputinginpractice:TheCondorexperi-\nence.ConcurrencyandComputation:PracticeandEx-\nperience, 2004.\n[17]L.G.Valiant.A bridgingmodelforparallelcomputation.\nCommunicationsoftheACM, 33(8):103ñ111,1997.\n[18]JimWyllie.Spsort:Howtosorta  terabytequickly.\nhttp://alme1.almaden.ibm.com/cs/spsort.pdf.\nAWordFrequency\nThissectioncontainsa programthatcountsthenumber\nofoccurrencesofeachuniquewordina setofinput\u0002les\nspeci\u0002edonthecommandline.\n#include\"mapreduce/mapreduce.h\"\n// User'smap function\nclassWordCounter: publicMapper{\npublic:\nvirtualvoidMap(constMapInput&input){\nconststring&text= input.value();\nconstint n = text.size();\nfor(inti = 0; i < n; ) {\n// Skippastleadingwhitespace\nwhile((i< n) && isspace(text[i]))\ni++;\n// Findwordend\nintstart= i;\nwhile((i< n) && !isspace(text[i]))\ni++;\nif (start< i)\nEmit(text.substr(start,i-start),\"1\");\n}\n}\n};\nREGISTER_MAPPER(WordCounter);\n// User'sreducefunction\nclassAdder: publicReducer{\nvirtualvoidReduce(ReduceInput*input){\n// Iterateoverall entrieswiththe\n// samekeyand add thevalues\nint64value= 0;\nwhile(!input->done()){\nvalue+= StringToInt(input->value());\ninput->NextValue();\n}\n// Emitsumfor input->key()\nEmit(IntToString(value));\n}\n};\nREGISTER_REDUCER(Adder);\nint main(intargc,char**argv){\nParseCommandLineFlags(argc,argv);\nMapReduceSpecificationspec;\n// Storelistof inputfilesinto\"spec\"\nfor (inti = 1; i < argc;i++){\nMapReduceInput*input= spec.add_input();\ninput->set_format(\"text\");\ninput->set_filepattern(argv[i]);\ninput->set_mapper_class(\"WordCounter\");\n}\n// Specifythe outputfiles:\n///gfs/test/freq-00000-of-00100\n///gfs/test/freq-00001-of-00100\n//...\nMapReduceOutput*out= spec.output();\nout->set_filebase(\"/gfs/test/freq\");\nout->set_num_tasks(100);\nout->set_format(\"text\");\nout->set_reducer_class(\"Adder\");\n// Optional:do partialsumswithinmap\n// tasksto savenetworkbandwidth\nout->set_combiner_class(\"Adder\");\n// Tuningparameters:useat most2000\n// machinesand 100MB of memoryper task\nspec.set_machines(2000);\nspec.set_map_megabytes(100);\nspec.set_reduce_megabytes(100);\n// Nowrun it\nMapReduceResultresult;\nif (!MapReduce(spec,&result))abort();\n// Done:'result'structurecontainsinfo\n// aboutcounters,timetaken,numberof\n// machinesused,etc.\nreturn0;\n}\nTo appearinOSDI200413"
  ]
}