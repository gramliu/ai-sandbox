{
  "input": "<metadata>\n{\n  \"title\": \"PDFTriage: Question Answering over Long, Structured Documents\",\n  \"abstract\": \"  Large Language Models (LLMs) have issues with document question answering\\n(QA) in situations where the document is unable to fit in the small context\\nlength of an LLM. To overcome this issue, most existing works focus on\\nretrieving the relevant context from the document, representing them as plain\\ntext. However, documents such as PDFs, web pages, and presentations are\\nnaturally structured with different pages, tables, sections, and so on.\\nRepresenting such structured documents as plain text is incongruous with the\\nuser's mental model of these documents with rich structure. When a system has\\nto query the document for context, this incongruity is brought to the fore, and\\nseemingly trivial questions can trip up the QA system. To bridge this\\nfundamental gap in handling structured documents, we propose an approach called\\nPDFTriage that enables models to retrieve the context based on either structure\\nor content. Our experiments demonstrate the effectiveness of the proposed\\nPDFTriage-augmented models across several classes of questions where existing\\nretrieval-augmented LLMs fail. To facilitate further research on this\\nfundamental problem, we release our benchmark dataset consisting of 900+\\nhuman-generated questions over 80 structured documents from 10 different\\ncategories of question types for document QA. Our code and datasets will be\\nreleased soon on Github.\\n\",\n  \"published\": \"2023-09-16T04:29:05Z\"\n}\n</metadata>\n<text>\nHere is a summary of the key points from the paper:\n\n**Overview**\n- The paper introduces PDFTriage, a technique for question answering over long, structured documents like PDFs, web pages, and presentations.\n- Current approaches often represent documents as plain text, which is incongruous with the rich structure of these documents and can lead to failure on seemingly trivial questions.\n- PDFTriage enables models to retrieve context based on either document structure or content, bridging this fundamental gap.\n\n**Key Contributions**\n1. Identified the gap in document QA with current LLM approaches that treat documents as plain text.\n2. Released a benchmark dataset of 900+ human-generated questions over 80 structured documents, covering 10 different question types.\n3. Presented the PDFTriage approach that leverages document structure metadata and retrieval functions to improve performance on document QA tasks.\n\n**Findings**\n- PDFTriage outperformed retrieval-based baselines, with annotators favoring PDFTriage answers over 50% of the time.\n- PDFTriage answers scored higher than baselines on measures of accuracy, informativeness, readability, and overall quality.\n- PDFTriage performance was consistent across documents of varying lengths, indicating it can handle both short and long documents effectively.\n\n**Example Questions and Answers**\nQ1: \"Can you summarize the key takeaways from pages 5-7?\"\nPDFTriage Answer: The key takeaways of pages 5-7 are...\nQ2: \"What year [in table 3] has the maximum revenue?\"\nPDFTriage Answer: The year in table 3 with the maximum revenue is...\n\n**Future Work**\n1. Develop multi-modal approaches incorporating table and figure information into LLM QA.\n2. Incorporate question type into the PDFTriage approach to improve efficiency and efficacy.</text>",
  "output": "Today I worked on implementing a new technique called PDFTriage for question answering over long, structured documents like PDFs and web pages. The key idea is to leverage the inherent structure and metadata in these documents to improve retrieval of relevant context for answering questions.\n\nIn the morning, I studied the PDFTriage paper and the benchmark dataset they released containing over 900 questions across 80 documents from 10 different categories. This gave me a good understanding of the types of questions where existing QA systems struggle due to treating documents as plain text.\n\nAfter lunch, I started coding up the PDFTriage approach in Python. I wrote functions to parse the structure metadata from PDF and HTML documents, identifying sections, tables, figures etc. I then implemented retrieval functions that can query this structured representation to find relevant context snippets for a given question.\n\nIn the evening, I integrated the PDFTriage retrieval module with a large language model for question answering. I fine-tuned the model on the benchmark dataset, comparing its performance with and without the PDFTriage context retrieval component. The results were quite promising - PDFTriage helped the model correctly answer many questions that required understanding the document structure.\n\nTo wrap up, I spent some time analyzing failure cases and brainstorming ways to further improve PDFTriage. Some ideas include incorporating table/figure understanding, using the question type to guide retrieval, and exploring multi-modal approaches. Overall, an exciting day working on a technique to bridge the gap between language models and real-world structured data!"
}