{
  "input": "<metadata>\n{\n  \"title\": \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your\\n  Phone\",\n  \"abstract\": \"  We introduce phi-3-mini, a 3.8 billion parameter language model trained on\\n3.3 trillion tokens, whose overall performance, as measured by both academic\\nbenchmarks and internal testing, rivals that of models such as Mixtral 8x7B and\\nGPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite\\nbeing small enough to be deployed on a phone. The innovation lies entirely in\\nour dataset for training, a scaled-up version of the one used for phi-2,\\ncomposed of heavily filtered web data and synthetic data. The model is also\\nfurther aligned for robustness, safety, and chat format. We also provide some\\ninitial parameter-scaling results with a 7B and 14B models trained for 4.8T\\ntokens, called phi-3-small and phi-3-medium, both significantly more capable\\nthan phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on\\nMT-bench).\\n\",\n  \"published\": \"2024-04-22T14:32:33Z\"\n}\n</metadata>\n<text>\nSummary:\nThis technical report introduces phi-3-mini, a compact 3.8 billion parameter language model that achieves performance rivaling much larger models like Mixtral 8x7B and GPT-3.5 on academic benchmarks and internal testing, while being small enough to run locally on a modern smartphone. The key innovation is in the training data, which consists of heavily filtered web data and synthetic data, similar to the approach used for phi-2. The model is also aligned for robustness, safety, and chat format. Initial scaling results with 7B and 14B parameter models (phi-3-small and phi-3-medium) show significant further performance gains.\n\nDespite its small size, phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench. The model's main limitation is factual knowledge due to capacity constraints, but this can be mitigated by augmenting it with a search engine. Safety and responsibility were key focuses, with the model undergoing safety alignment, red-teaming, and automated testing. However, challenges remain around factual inaccuracies, bias, inappropriate content, and safety issues that still need to be fully addressed.\n\nKeywords: compact language models, filtered training data, on-device inference, model scaling, responsible AI\n\nExample Questions:\nQ: How does the performance of phi-3-mini compare to state-of-the-art large language models when evaluated on standard academic NLP benchmarks?\nQ: What techniques were used to ensure phi-3-mini behaves in a safe, robust, and responsible manner during open-ended interactions with humans?\nQ: How might the ability to run highly capable language models like phi-3-mini directly on consumer devices change the way AI assistants are developed and deployed in the future?\nQ: What are some potential beneficial applications of a model like phi-3-mini that can perform advanced language tasks while preserving user privacy by running fully on-device?</text>",
  "output": "Today I worked on exploring the capabilities of the new phi-3-mini language model from OpenAI. This compact 3.8 billion parameter model can run locally on a smartphone yet performs remarkably well on NLP benchmarks, rivaling much larger models.\n\nIn the morning, I downloaded the phi-3-mini model and set it up on my phone. I was impressed by how quickly it loaded given its size. I spent some time going through the documentation and examples to understand its training process using filtered web data and synthetic data.\n\nFor the afternoon, I decided to put phi-3-mini through its paces. I tried it on various language tasks like question-answering, text summarization, and even some light creative writing prompts. The results were quite impressive - the model demonstrated strong language understanding and generation capabilities despite its compact size.\n\nI also explored some of the safety and alignment techniques used during phi-3-mini's training, like red-teaming and automated testing for potential risks. While not perfect, it seemed to handle sensitive topics reasonably well.\n\nIn the evening, I experimented with running phi-3-mini in tandem with a search engine to augment its factual knowledge. This allowed me to get more accurate and up-to-date information compared to just relying on the model's training data alone.\n\nOverall, I'm really excited about the potential of highly capable yet compact language models like phi-3-mini. Being able to run them locally on-device opens up many privacy-preserving applications. I'll definitely be following the development of larger phi-3 models and their real-world use cases."
}