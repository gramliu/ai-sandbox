{
  "input": "<metadata>\n{\n  \"title\": \"Better Synthetic Data by Retrieving and Transforming Existing Datasets\",\n  \"abstract\": \"  Despite recent advances in large language models, building dependable and\\ndeployable NLP models typically requires abundant, high-quality training data.\\nHowever, task-specific data is not available for many use cases, and manually\\ncurating task-specific data is labor-intensive. Recent work has studied\\nprompt-driven synthetic data generation using large language models, but these\\ngenerated datasets tend to lack complexity and diversity. To address these\\nlimitations, we introduce a method, DataTune, to make better use of existing,\\npublicly available datasets to improve automatic dataset generation. DataTune\\nperforms dataset transformation, enabling the repurposing of publicly available\\ndatasets into a format that is directly aligned with the specific requirements\\nof target tasks. On a diverse set of language-based tasks from the BIG-Bench\\nbenchmark, we find that finetuning language models via DataTune improves over a\\nfew-shot prompting baseline by 49% and improves over existing methods that use\\nsynthetic or retrieved training data by 34%. We find that dataset\\ntransformation significantly increases the diversity and difficulty of\\ngenerated data on many tasks. We integrate DataTune into an open-source\\nrepository to make this method accessible to the community:\\nhttps://github.com/neulab/prompt2model.\\n\",\n  \"published\": \"2024-04-22T17:15:32Z\"\n}\n</metadata>\n<text>\nSummary:\nThis paper introduces DataTune, a method for improving automatic dataset generation by transforming existing labeled datasets to better align with the requirements of a target task. The key innovations are:\n\n1. Dataset Retrieval: DataTune uses a two-stage retrieval process to identify relevant existing datasets, first using a dense retriever and then reranking the results using a large language model.\n\n2. Dataset Transformation: DataTune uses a planning module to devise a step-by-step transformation plan to adapt the retrieved dataset to the target task format. This plan is then executed by a separate module to generate the final synthetic dataset.\n\nThe authors evaluate DataTune on 6 diverse language tasks from the BIG-Bench benchmark and find that it:\n\n- Outperforms few-shot prompting and existing data collection methods by 6.4 points on average.\n- Generates more diverse and challenging examples compared to direct synthetic data generation.\n- Can be combined with synthetic data generation for additive performance improvements.\n- Outperforms the state-of-the-art Prompt2Model approach by 8.3 points on average.\n\nKeywords: dataset generation, dataset transformation, few-shot learning, language models\n\nExample Questions:\nQ: How does DataTune's approach of transforming existing datasets differ from directly generating synthetic data using language models?\nA: DataTune aims to leverage the diversity and complexity of existing datasets, rather than generating data directly from language models, which tends to produce simpler and less diverse examples.\n\nQ: What are the key steps involved in DataTune's dataset transformation process?\nA: DataTune first retrieves relevant existing datasets, then uses a planning module to devise a step-by-step transformation plan to adapt the dataset to the target task format. This plan is then executed by a separate module to generate the final synthetic dataset.\n\nQ: How does the combination of DataTune and synthetic data generation outperform other few-shot learning approaches on the BIG-Bench tasks?\nA: The authors find that DataTune and synthetic data generation are complementary, with the transformed datasets from DataTune covering different regions of the task space compared to directly generated synthetic data. Combining the two approaches leads to additive performance improvements over using either method alone.\n\nQ: What are some potential limitations of the DataTune approach discussed in the paper?\nA: Key limitations include the high cost of querying large language models for the dataset transformation, the dependence on the planning module producing accurate transformation plans, and challenges in handling non-English data.</text>",
  "output": "Today I worked on exploring the new DataTune method for generating high-quality training datasets for machine learning models. The key idea is to retrieve and transform existing labeled datasets to better match the target task, rather than generating synthetic data from scratch.\n\nIn the morning, I spent some time reading through the DataTune paper and exploring the open-source code repository. I was really intrigued by the two-stage dataset retrieval process using dense retrieval and language model reranking. It seems like a clever way to identify relevant existing datasets for a given task.\n\nAfter lunch, I decided to try out DataTune on a few language tasks I've been working on. I defined the task requirements, let DataTune retrieve some candidate datasets, and then used the planning module to generate transformation steps. I have to say, the resulting transformed datasets look really promising - much more diverse and challenging than what I could generate synthetically.\n\nIn the evening, I experimented with combining the transformed DataTune datasets with some synthetic data I had previously generated. Just as the paper claimed, I saw additive performance gains over using either approach alone. The transformed data seems to cover different areas of the task space compared to my synthetic examples.\n\nOverall, I'm really excited about the potential of DataTune. Being able to effectively reuse and transform existing datasets could be a game-changer, especially for domains where curating new labeled data is expensive. I plan to integrate DataTune into my data preparation pipelines going forward. The open-source repository makes it easy to get started."
}