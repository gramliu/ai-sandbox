{
  "input": "<metadata>\n{\n  \"title\": \"Voyager: An Open-Ended Embodied Agent with Large Language Models\",\n  \"abstract\": \"  We introduce Voyager, the first LLM-powered embodied lifelong learning agent\\nin Minecraft that continuously explores the world, acquires diverse skills, and\\nmakes novel discoveries without human intervention. Voyager consists of three\\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an\\never-growing skill library of executable code for storing and retrieving\\ncomplex behaviors, and 3) a new iterative prompting mechanism that incorporates\\nenvironment feedback, execution errors, and self-verification for program\\nimprovement. Voyager interacts with GPT-4 via blackbox queries, which bypasses\\nthe need for model parameter fine-tuning. The skills developed by Voyager are\\ntemporally extended, interpretable, and compositional, which compounds the\\nagent's abilities rapidly and alleviates catastrophic forgetting. Empirically,\\nVoyager shows strong in-context lifelong learning capability and exhibits\\nexceptional proficiency in playing Minecraft. It obtains 3.3x more unique\\nitems, travels 2.3x longer distances, and unlocks key tech tree milestones up\\nto 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill\\nlibrary in a new Minecraft world to solve novel tasks from scratch, while other\\ntechniques struggle to generalize. We open-source our full codebase and prompts\\nat https://voyager.minedojo.org/.\\n\",\n  \"published\": \"2023-05-25T17:46:38Z\"\n}\n</metadata>\n<text>\nSummary:\n\nThis paper introduces Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft. Voyager consists of three key components:\n\n1. An automatic curriculum that maximizes exploration and proposes progressively harder tasks.\n2. A skill library that stores and retrieves complex executable behaviors.\n3. An iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification to improve code generation.\n\nVoyager interacts with GPT-4 via blackbox queries, bypassing the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, enabling rapid capability growth and mitigating catastrophic forgetting.\n\nEmpirically, Voyager exhibits strong in-context lifelong learning capabilities. It outperforms prior state-of-the-art methods by obtaining 3.3x more unique items, unlocking key tech tree milestones up to 15.3x faster, and traversing 2.3x longer distances. Voyager can also utilize its learned skill library to solve novel tasks from scratch in a new Minecraft world, while other techniques struggle to generalize.\n\nKeywords: embodied agents, lifelong learning, large language models, Minecraft\n\nExample Questions:\n\nQ: How does Voyager's automatic curriculum differ from manually designed curricula, and what are the benefits of the automatic approach?\nA: Voyager's automatic curriculum is generated by GPT-4 based on the goal of \"discovering as many diverse things as possible\", allowing it to adapt to the agent's current state and exploration progress. This is more scalable and flexible than manually designing a fixed curriculum, which requires significant domain expertise.\n\nQ: What is the role of the skill library in Voyager's performance, and how does it enable rapid capability growth and generalization?\nA: The skill library stores executable programs that represent complex behaviors. By composing and reusing these skills, Voyager can quickly develop new capabilities without starting from scratch. The skill library also allows Voyager to apply its learned skills to solve novel tasks in a new Minecraft world, demonstrating strong generalization.\n\nQ: How does Voyager's iterative prompting mechanism, which incorporates environment feedback and self-verification, improve the quality of the generated code compared to a one-shot approach?\nA: The iterative prompting mechanism allows Voyager to refine its code generation based on execution feedback and errors, as well as self-assess whether the generated code successfully completes the task. This iterative process leads to more robust and reliable code compared to a one-shot approach.\n\nQ: How could Voyager's capabilities be further enhanced by incorporating multimodal perception, such as visual input from the Minecraft environment?\nA: While the current version of Voyager is text-only, the authors demonstrate that it can be augmented with human visual feedback to construct complex 3D structures. Integrating multimodal perception models could allow Voyager to better understand and interact with the 3D environment, potentially leading to even more impressive task-solving abilities.</text>",
  "output": "Today I worked on developing an embodied AI agent called Voyager that can learn and explore the world of Minecraft autonomously. Here are the key things I did:\n\n- Implemented an automatic curriculum generation system using GPT-4 that proposes progressively harder tasks for Voyager to tackle, maximizing its exploration and learning.\n\n- Created a skill library that stores executable code representing complex behaviors Voyager has learned. This allows Voyager to compose and reuse skills to rapidly develop new capabilities.\n\n- Developed an iterative prompting mechanism that incorporates feedback from Voyager's actions in the Minecraft environment. This mechanism uses execution errors and self-verification to refine the code generated by GPT-4, improving its robustness.\n\n- Tested Voyager in the Minecraft environment and was amazed by its ability to acquire diverse skills without human intervention. Compared to previous approaches, Voyager obtained 3.3x more unique items, traveled 2.3x longer distances, and unlocked key milestones up to 15.3x faster!\n\n- Excitingly, Voyager can take its learned skill library and use it to solve entirely new tasks from scratch in a different Minecraft world, demonstrating strong generalization abilities that other techniques struggle with.\n\nI'm really proud of the progress we've made with Voyager. Integrating large language models with embodied agents in this lifelong learning framework opens up so many possibilities for autonomous exploration and capability acquisition. I can't wait to see what other domains Voyager could be applied to next!"
}