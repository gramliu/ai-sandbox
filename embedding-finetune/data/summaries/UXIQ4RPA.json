{
  "text": "Here is a summary of the key points from the paper:\n\n**Overview**\n- The paper introduces PDFTriage, a technique for question answering over long, structured documents like PDFs, web pages, and presentations.\n- Current approaches often represent documents as plain text, which is incongruous with the rich structure of these documents and can lead to failure on seemingly trivial questions.\n- PDFTriage enables models to retrieve context based on either document structure or content, bridging this fundamental gap.\n\n**Key Contributions**\n1. Identified the gap in document QA with current LLM approaches that treat documents as plain text.\n2. Released a benchmark dataset of 900+ human-generated questions over 80 structured documents, covering 10 different question types.\n3. Presented the PDFTriage approach that leverages document structure metadata and retrieval functions to improve performance on document QA tasks.\n\n**Findings**\n- PDFTriage outperformed retrieval-based baselines, with annotators favoring PDFTriage answers over 50% of the time.\n- PDFTriage answers scored higher than baselines on measures of accuracy, informativeness, readability, and overall quality.\n- PDFTriage performance was consistent across documents of varying lengths, indicating it can handle both short and long documents effectively.\n\n**Example Questions and Answers**\nQ1: \"Can you summarize the key takeaways from pages 5-7?\"\nPDFTriage Answer: The key takeaways of pages 5-7 are...\nQ2: \"What year [in table 3] has the maximum revenue?\"\nPDFTriage Answer: The year in table 3 with the maximum revenue is...\n\n**Future Work**\n1. Develop multi-modal approaches incorporating table and figure information into LLM QA.\n2. Incorporate question type into the PDFTriage approach to improve efficiency and efficacy.",
  "metadata": {
    "title": "PDFTriage: Question Answering over Long, Structured Documents",
    "abstract": "  Large Language Models (LLMs) have issues with document question answering\n(QA) in situations where the document is unable to fit in the small context\nlength of an LLM. To overcome this issue, most existing works focus on\nretrieving the relevant context from the document, representing them as plain\ntext. However, documents such as PDFs, web pages, and presentations are\nnaturally structured with different pages, tables, sections, and so on.\nRepresenting such structured documents as plain text is incongruous with the\nuser's mental model of these documents with rich structure. When a system has\nto query the document for context, this incongruity is brought to the fore, and\nseemingly trivial questions can trip up the QA system. To bridge this\nfundamental gap in handling structured documents, we propose an approach called\nPDFTriage that enables models to retrieve the context based on either structure\nor content. Our experiments demonstrate the effectiveness of the proposed\nPDFTriage-augmented models across several classes of questions where existing\nretrieval-augmented LLMs fail. To facilitate further research on this\nfundamental problem, we release our benchmark dataset consisting of 900+\nhuman-generated questions over 80 structured documents from 10 different\ncategories of question types for document QA. Our code and datasets will be\nreleased soon on Github.\n",
    "published": "2023-09-16T04:29:05Z"
  }
}