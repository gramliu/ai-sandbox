{
  "text": "Summary:\nThis paper introduces DataTune, a method for improving automatic dataset generation by transforming existing labeled datasets to better align with the requirements of a target task. The key innovations are:\n\n1. Dataset Retrieval: DataTune uses a two-stage retrieval process to identify relevant existing datasets, first using a dense retriever and then reranking the results using a large language model.\n\n2. Dataset Transformation: DataTune uses a planning module to devise a step-by-step transformation plan to adapt the retrieved dataset to the target task format. This plan is then executed by a separate module to generate the final synthetic dataset.\n\nThe authors evaluate DataTune on 6 diverse language tasks from the BIG-Bench benchmark and find that it:\n\n- Outperforms few-shot prompting and existing data collection methods by 6.4 points on average.\n- Generates more diverse and challenging examples compared to direct synthetic data generation.\n- Can be combined with synthetic data generation for additive performance improvements.\n- Outperforms the state-of-the-art Prompt2Model approach by 8.3 points on average.\n\nKeywords: dataset generation, dataset transformation, few-shot learning, language models\n\nExample Questions:\nQ: How does DataTune's approach of transforming existing datasets differ from directly generating synthetic data using language models?\nA: DataTune aims to leverage the diversity and complexity of existing datasets, rather than generating data directly from language models, which tends to produce simpler and less diverse examples.\n\nQ: What are the key steps involved in DataTune's dataset transformation process?\nA: DataTune first retrieves relevant existing datasets, then uses a planning module to devise a step-by-step transformation plan to adapt the dataset to the target task format. This plan is then executed by a separate module to generate the final synthetic dataset.\n\nQ: How does the combination of DataTune and synthetic data generation outperform other few-shot learning approaches on the BIG-Bench tasks?\nA: The authors find that DataTune and synthetic data generation are complementary, with the transformed datasets from DataTune covering different regions of the task space compared to directly generated synthetic data. Combining the two approaches leads to additive performance improvements over using either method alone.\n\nQ: What are some potential limitations of the DataTune approach discussed in the paper?\nA: Key limitations include the high cost of querying large language models for the dataset transformation, the dependence on the planning module producing accurate transformation plans, and challenges in handling non-English data.",
  "metadata": {
    "title": "Better Synthetic Data by Retrieving and Transforming Existing Datasets",
    "abstract": "  Despite recent advances in large language models, building dependable and\ndeployable NLP models typically requires abundant, high-quality training data.\nHowever, task-specific data is not available for many use cases, and manually\ncurating task-specific data is labor-intensive. Recent work has studied\nprompt-driven synthetic data generation using large language models, but these\ngenerated datasets tend to lack complexity and diversity. To address these\nlimitations, we introduce a method, DataTune, to make better use of existing,\npublicly available datasets to improve automatic dataset generation. DataTune\nperforms dataset transformation, enabling the repurposing of publicly available\ndatasets into a format that is directly aligned with the specific requirements\nof target tasks. On a diverse set of language-based tasks from the BIG-Bench\nbenchmark, we find that finetuning language models via DataTune improves over a\nfew-shot prompting baseline by 49% and improves over existing methods that use\nsynthetic or retrieved training data by 34%. We find that dataset\ntransformation significantly increases the diversity and difficulty of\ngenerated data on many tasks. We integrate DataTune into an open-source\nrepository to make this method accessible to the community:\nhttps://github.com/neulab/prompt2model.\n",
    "published": "2024-04-22T17:15:32Z"
  }
}