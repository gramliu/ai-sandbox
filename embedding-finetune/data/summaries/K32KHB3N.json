{
  "text": "Summary:\n\nThis paper introduces the RAGGED framework to analyze and optimize retrieval-augmented generation (RAG) systems. The key findings are:\n\n1. Different language models (LMs) benefit from varied RAG setups. Encoder-decoder models like FLAN can effectively utilize up to 30 retrieved passages, while decoder-only models like LLAMA can only effectively use < 5 passages despite having longer context windows.\n\n2. The differences in context utilization are due to the models' reliance on provided contexts vs. memorized knowledge. Encoder-decoder models rely more on contexts and are more sensitive to retrieval quality, while decoder-only models tend to rely more on their pre-trained knowledge.\n\n3. The quality of the retriever has a larger impact on encoder-decoder models, especially for single-hop questions. Neural retrievers like ColBERT provide significant benefits over sparse retrievers like BM25 for open-domain questions, but the benefits are less pronounced for decoder-only models and multi-hop questions.\n\nKeywords: retrieval-augmented generation, context utilization, retriever quality, language model architecture\n\nExample Questions:\n1. How do the context utilization behaviors of encoder-decoder and decoder-only language models differ, and what are the implications for RAG system design?\n2. Under what conditions do neural retrievers like ColBERT provide the most significant benefits over sparse retrievers like BM25 for RAG systems?\n3. How can the RAGGED framework be used to analyze the performance of new RAG components as they evolve?",
  "metadata": {
    "title": "RAGGED: Towards Informed Design of Retrieval Augmented Generation\n  Systems",
    "abstract": "  Retrieval-augmented generation (RAG) greatly benefits language models (LMs)\nby providing additional context for tasks such as document-based question\nanswering (DBQA). Despite its potential, the power of RAG is highly dependent\non its configuration, raising the question: What is the optimal RAG\nconfiguration? To answer this, we introduce the RAGGED framework to analyze and\noptimize RAG systems. On a set of representative DBQA tasks, we study two\nclassic sparse and dense retrievers, and four top-performing LMs in\nencoder-decoder and decoder-only architectures. Through RAGGED, we uncover that\ndifferent models suit substantially varied RAG setups. While encoder-decoder\nmodels monotonically improve with more documents, we find decoder-only models\ncan only effectively use &lt; 5 documents, despite often having a longer context\nwindow. RAGGED offers further insights into LMs' context utilization habits,\nwhere we find that encoder-decoder models rely more on contexts and are thus\nmore sensitive to retrieval quality, while decoder-only models tend to rely on\nknowledge memorized during training.\n",
    "published": "2024-03-14T02:26:31Z"
  }
}