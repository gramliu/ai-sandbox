{
  "text": "Summary:\n\nThe paper introduces MineDojo, a new framework for developing generally capable embodied agents. MineDojo features:\n\n1. A benchmarking suite with thousands of diverse open-ended tasks in Minecraft, including both programmatic tasks with clear success criteria and creative tasks without straightforward evaluation.\n\n2. An internet-scale, multimodal knowledge base of Minecraft-related YouTube videos, Wiki pages, and Reddit discussions, capturing the collective experience and wisdom of millions of players.\n\n3. A novel agent learning algorithm that leverages this internet-scale data. The key innovation is MineCLIP, a contrastive video-language model trained on the YouTube videos, which can be used as an effective open-vocabulary reward function for reinforcement learning.\n\nThe authors show that agents trained with MineCLIP can solve a variety of complex tasks, often matching or outperforming agents trained with manually engineered dense rewards. For creative tasks without clear success criteria, MineCLIP also serves as an automatic evaluation metric that agrees well with human judgments.\n\nThe paper highlights the importance of open-ended environments, large-scale knowledge bases, and flexible agent architectures for developing generally capable embodied AI systems. The MineDojo framework and resources are open-sourced to promote further research in this direction.\n\nKeywords: open-ended environments, internet-scale knowledge, video-language models, reinforcement learning\n\nExample Questions:\n\nQ: How does the performance of the MineCLIP-based agent compare to agents trained with manually engineered dense rewards on the programmatic tasks in MineDojo?\nA: The MineCLIP-based agent achieves competitive performance compared to agents trained with manually engineered dense rewards, and in some cases even outperforms them, with up to 73% improvement in success rates.\n\nQ: How does the MineCLIP model serve as an automatic evaluation metric for the creative tasks in MineDojo that lack clear success criteria?\nA: The authors show that the MineCLIP model's output correlates well with human judgments on a subset of the creative tasks, achieving F1 scores above 95% in some cases. This allows MineCLIP to be used as an effective automatic evaluation metric for these open-ended tasks.\n\nQ: How does the internet-scale, multimodal knowledge base of Minecraft data collected in MineDojo enable new research directions for embodied AI agents?\nA: The diverse data sources, including YouTube videos, Wiki pages, and Reddit discussions, provide a rich source of Minecraft-related knowledge that agents can leverage. The authors suggest this data could be used to train large language models, extract hierarchical planning knowledge, and generate instructional text, opening up new possibilities for developing generally capable agents.",
  "metadata": {
    "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale\n  Knowledge",
    "abstract": "  Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (https://minedojo.org) to promote\nresearch towards the goal of generally capable embodied agents.\n",
    "published": "2022-06-17T15:53:05Z"
  }
}