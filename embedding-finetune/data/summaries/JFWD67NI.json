{
  "text": "Summary:\nThis paper introduces a new framework called \"Tree of Thoughts\" (ToT) that enables language models to perform more deliberate problem-solving by exploring multiple reasoning paths and evaluating choices through self-reflection. The key ideas are:\n\n1. Decomposing the problem-solving process into coherent \"thoughts\" that serve as intermediate steps, rather than just generating a continuous sequence.\n2. Generating and evaluating multiple candidate thoughts at each step, using prompts that allow the language model to reason about the viability of different options.\n3. Incorporating search algorithms like breadth-first search and depth-first search to systematically explore the tree of thoughts, looking ahead and backtracking as needed.\n\nThe authors evaluate ToT on three novel tasks - Game of 24, Creative Writing, and Mini Crosswords - that challenge the standard left-to-right, token-level decision making of language models. They show that ToT significantly outperforms standard prompting methods like input-output and chain-of-thought on these tasks.\n\nKeywords: language models, problem-solving, planning, search, deliberate reasoning\n\nExample Questions:\nQ: How does the Tree of Thoughts framework differ from standard language model prompting approaches like input-output and chain-of-thought?\nA: ToT decomposes the problem-solving process into coherent \"thoughts\" that are explored and evaluated in a tree-like structure, rather than just generating a continuous sequence. This allows the language model to reason about multiple potential solution paths and make more deliberate decisions.\n\nQ: What are the key components of the ToT framework, and how can they be customized for different problem domains?\nA: The key components are: 1) thought decomposition, 2) thought generation, 3) state evaluation, and 4) search algorithm. These can be tailored based on the nature of the problem, the capabilities of the language model, and resource constraints.\n\nQ: How does the performance of ToT compare to standard prompting methods on the three novel tasks presented in the paper (Game of 24, Creative Writing, Mini Crosswords)?\nA: ToT significantly outperforms input-output and chain-of-thought prompting on all three tasks. For example, on Game of 24, while GPT-4 with chain-of-thought only solved 4% of tasks, ToT achieved a 74% success rate.\n\nQ: What are some potential applications and future directions for the Tree of Thoughts framework beyond the tasks explored in this paper?\nA: The authors suggest ToT could be useful for a wide range of real-world decision making applications that require planning, exploration, and deliberate reasoning, such as coding, data analysis, and robotics. Future work could explore fine-tuning language models specifically for ToT-style high-level counterfactual decision making.",
  "metadata": {
    "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
    "abstract": "  Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nhttps://github.com/princeton-nlp/tree-of-thought-llm.\n",
    "published": "2023-05-17T23:16:17Z"
  }
}