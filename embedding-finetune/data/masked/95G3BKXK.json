{
  "input": "<reference id=\"95G3BKXK\">\n<metadata>\n{\n  \"title\": \"Voyager: An Open-Ended Embodied Agent with Large Language Models\",\n  \"abstract\": \"  We introduce Voyager, the first LLM-powered embodied lifelong learning agent\\nin Minecraft that continuously explores the world, acquires diverse skills, and\\nmakes novel discoveries without human intervention. Voyager consists of three\\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an\\never-growing skill library of executable code for storing and retrieving\\ncomplex behaviors, and 3) a new iterative prompting mechanism that incorporates\\nenvironment feedback, execution errors, and self-verification for program\\nimprovement. Voyager interacts with GPT-4 via blackbox queries, which bypasses\\nthe need for model parameter fine-tuning. The skills developed by Voyager are\\ntemporally extended, interpretable, and compositional, which compounds the\\nagent's abilities rapidly and alleviates catastrophic forgetting. Empirically,\\nVoyager shows strong in-context lifelong learning capability and exhibits\\nexceptional proficiency in playing Minecraft. It obtains 3.3x more unique\\nitems, travels 2.3x longer distances, and unlocks key tech tree milestones up\\nto 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill\\nlibrary in a new Minecraft world to solve novel tasks from scratch, while other\\ntechniques struggle to generalize. We open-source our full codebase and prompts\\nat https://voyager.minedojo.org/.\\n\",\n  \"published\": \"2023-05-25T17:46:38Z\"\n}\n</metadata>\n<text>\nSummary:\n\nThis paper introduces Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft. Voyager consists of three key components:\n\n1. An automatic curriculum that maximizes exploration and proposes progressively harder tasks.\n2. A skill library that stores and retrieves complex executable behaviors.\n3. An iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification to improve code generation.\n\nVoyager interacts with GPT-4 via blackbox queries, bypassing the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, enabling rapid capability growth and mitigating catastrophic forgetting.\n\nEmpirically, Voyager exhibits strong in-context lifelong learning capabilities. It outperforms prior state-of-the-art methods by obtaining 3.3x more unique items, unlocking key tech tree milestones up to 15.3x faster, and traversing 2.3x longer distances. Voyager can also utilize its learned skill library to solve novel tasks from scratch in a new Minecraft world, while other techniques struggle to generalize.\n\nKeywords: embodied agents, lifelong learning, large language models, Minecraft\n\nExample Questions:\n\nQ: How does Voyager's automatic curriculum differ from manually designed curricula, and what are the benefits of the automatic approach?\nA: Voyager's automatic curriculum is generated by GPT-4 based on the goal of \"discovering as many diverse things as possible\", allowing it to adapt to the agent's current state and exploration progress. This is more scalable and flexible than manually designing a fixed curriculum, which requires significant domain expertise.\n\nQ: What is the role of the skill library in Voyager's performance, and how does it enable rapid capability growth and generalization?\nA: The skill library stores executable programs that represent complex behaviors. By composing and reusing these skills, Voyager can quickly develop new capabilities without starting from scratch. The skill library also allows Voyager to apply its learned skills to solve novel tasks in a new Minecraft world, demonstrating strong generalization.\n\nQ: How does Voyager's iterative prompting mechanism, which incorporates environment feedback and self-verification, improve the quality of the generated code compared to a one-shot approach?\nA: The iterative prompting mechanism allows Voyager to refine its code generation based on execution feedback and errors, as well as self-assess whether the generated code successfully completes the task. This iterative process leads to more robust and reliable code compared to a one-shot approach.\n\nQ: How could Voyager's capabilities be further enhanced by incorporating multimodal perception, such as visual input from the Minecraft environment?\nA: While the current version of Voyager is text-only, the authors demonstrate that it can be augmented with human visual feedback to construct complex 3D structures. Integrating multimodal perception models could allow Voyager to better understand and interact with the 3D environment, potentially leading to even more impressive task-solving abilities.\n</text>\n</reference>",
  "output": "<summary>\nThe paper explores the field of embodied lifelong learning agents, focusing on methods that enable continuous exploration and skill acquisition in virtual environments. It emphasizes the use of automatic curricula to drive exploration, skill libraries to store and retrieve complex behaviors, and iterative prompting mechanisms to refine code generation based on feedback. These methods collectively enhance the agent's ability to learn and generalize new tasks without human intervention, showcasing significant improvements over previous approaches.\n</summary>"
}