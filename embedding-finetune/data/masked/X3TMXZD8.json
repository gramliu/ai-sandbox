{
  "input": "<reference id=\"X3TMXZD8\">\n<metadata>\n{\n  \"title\": \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\",\n  \"abstract\": \"  Language models are increasingly being deployed for general problem solving\\nacross a wide range of tasks, but are still confined to token-level,\\nleft-to-right decision-making processes during inference. This means they can\\nfall short in tasks that require exploration, strategic lookahead, or where\\ninitial decisions play a pivotal role. To surmount these challenges, we\\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\\nwhich generalizes over the popular Chain of Thought approach to prompting\\nlanguage models, and enables exploration over coherent units of text (thoughts)\\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\\nperform deliberate decision making by considering multiple different reasoning\\npaths and self-evaluating choices to decide the next course of action, as well\\nas looking ahead or backtracking when necessary to make global choices. Our\\nexperiments show that ToT significantly enhances language models'\\nproblem-solving abilities on three novel tasks requiring non-trivial planning\\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\\nhttps://github.com/princeton-nlp/tree-of-thought-llm.\\n\",\n  \"published\": \"2023-05-17T23:16:17Z\"\n}\n</metadata>\n<text>\nSummary:\nThis paper introduces a new framework called \"Tree of Thoughts\" (ToT) that enables language models to perform more deliberate problem-solving by exploring multiple reasoning paths and evaluating choices through self-reflection. The key ideas are:\n\n1. Decomposing the problem-solving process into coherent \"thoughts\" that serve as intermediate steps, rather than just generating a continuous sequence.\n2. Generating and evaluating multiple candidate thoughts at each step using prompts that leverage the language model's own reasoning capabilities. \n3. Combining this thought generation and evaluation with search algorithms like breadth-first search and depth-first search to systematically explore the space of possible solutions.\n\nThe authors evaluate ToT on three novel tasks - Game of 24, Creative Writing, and Mini Crosswords - that challenge the token-level, left-to-right decision making of standard language models. They show ToT significantly outperforms standard prompting approaches on these tasks, achieving success rates up to 74% compared to 4-49% for baselines.\n\nKeywords: language models, problem solving, planning, search, deliberate reasoning\n\nExample Questions:\nQ: How does the Tree of Thoughts framework differ from standard language model prompting approaches like chain-of-thought?\nA: ToT decomposes the problem-solving process into coherent \"thoughts\" that are generated and evaluated independently, rather than just generating a continuous sequence. It also integrates this thought generation/evaluation with systematic search algorithms to explore multiple possible solutions.\n\nQ: What are the key components of the ToT framework, and how can they be customized for different problem domains?\nA: The key components are: 1) Thought decomposition, 2) Thought generation, 3) State evaluation, and 4) Search algorithm. These can be varied independently to adapt ToT to different problems, e.g. using different prompts for thought generation, different heuristics for state evaluation, and different search algorithms.\n\nQ: How could the ability to run highly capable language models like the one used in this paper directly on consumer devices impact the development and deployment of AI assistants in the future?\nA: (No definitive answer provided, as the paper does not speculate on this specific application.)\n\nQ: What are some potential beneficial applications of a model like the one described that can perform advanced language tasks while preserving user privacy by running fully on-device?\nA: Potential applications include: 1) Privacy-preserving mobile AI assistants that can engage in open-ended dialogue and help with tasks without sending user data to the cloud, 2) Embedded NLP systems for domains like healthcare where privacy is critical, and 3) Democratizing advanced language AI capabilities to developers/researchers without access to massive computing resources.\n</text>\n</reference>",
  "output": "<summary>\nThe paper explores the field of enhancing problem-solving capabilities in language models. It focuses on improving the decision-making process by breaking down tasks into intermediate steps and evaluating multiple potential solutions. The approach integrates systematic search algorithms to explore various reasoning paths, allowing for more strategic and deliberate problem-solving. This method aims to overcome the limitations of traditional token-level, sequential decision-making in language models.\n</summary>"
}