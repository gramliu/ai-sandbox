{
  "input": "<reference id=\"6D29SZKT\">\n<metadata>\n{\n  \"title\": \"ReALM: Reference Resolution As Language Modeling\",\n  \"abstract\": \"  Reference resolution is an important problem, one that is essential to\\nunderstand and successfully handle context of different kinds. This context\\nincludes both previous turns and context that pertains to non-conversational\\nentities, such as entities on the user's screen or those running in the\\nbackground. While LLMs have been shown to be extremely powerful for a variety\\nof tasks, their use in reference resolution, particularly for\\nnon-conversational entities, remains underutilized. This paper demonstrates how\\nLLMs can be used to create an extremely effective system to resolve references\\nof various types, by showing how reference resolution can be converted into a\\nlanguage modeling problem, despite involving forms of entities like those on\\nscreen that are not traditionally conducive to being reduced to a text-only\\nmodality. We demonstrate large improvements over an existing system with\\nsimilar functionality across different types of references, with our smallest\\nmodel obtaining absolute gains of over 5% for on-screen references. We also\\nbenchmark against GPT-3.5 and GPT-4, with our smallest model achieving\\nperformance comparable to that of GPT-4, and our larger models substantially\\noutperforming it.\\n\",\n  \"published\": \"2024-03-29T17:59:06Z\"\n}\n</metadata>\n<text>\nThis paper introduces ReALM, a language modeling approach to reference resolution that can handle different types of references, including those to on-screen entities, conversational entities, and background entities. The key contributions are:\n\n1. Formulating reference resolution as a language modeling problem, allowing the use of large language models (LLMs) for this task.\n\n2. Developing a novel technique to encode on-screen entities into a textual representation that can be processed by the LLM, preserving the relative spatial information.\n\n3. Demonstrating that ReALM outperforms a specialized non-LLM baseline system (MARRS) across different reference types, and achieves performance comparable to or better than the state-of-the-art LLM, GPT-4, despite using significantly fewer parameters.\n\nThe results show that ReALM achieves 96.7-99.8% accuracy on conversational and synthetic datasets, and 88.9-93.0% on on-screen reference datasets, outperforming the MARRS baseline. ReALM also matches the performance of GPT-4 on an unseen \"alarms\" dataset, and outperforms GPT-4 on domain-specific queries.\n\nThe key advantages of the ReALM approach are:\n\n1. Ability to handle different reference types (conversational, on-screen, background) using a single, flexible model.\n2. Strong performance despite a much smaller model size compared to large LLMs like GPT-4.\n3. Potential for on-device deployment due to the compact model size.\n4. Ease of integration into existing pipelines compared to end-to-end approaches.\n\nOverall, this work demonstrates the power of language modeling for reference resolution, and provides a practical solution that can be deployed in real-world conversational agents.\n\nExample Questions:\n\nQ: How does the ReALM approach differ from traditional reference resolution systems?\nA: ReALM formulates reference resolution as a language modeling problem, allowing the use of large language models, unlike traditional systems that rely on rule-based or feature-engineering approaches.\n\nQ: What is the key innovation in how ReALM encodes on-screen entities for the language model?\nA: ReALM uses a novel algorithm to convert the spatial layout of on-screen entities into a textual representation that preserves the relative positions, enabling the language model to effectively process this information.\n\nQ: How does the performance of ReALM compare to state-of-the-art language models like GPT-4?\nA: ReALM achieves comparable or better performance than GPT-4 on reference resolution tasks, despite using a significantly smaller model size. ReALM also outperforms GPT-4 on domain-specific queries.\n\nQ: What are some potential real-world applications of the ReALM approach?\nA: ReALM could be used to build more natural and effective conversational agents, especially for on-device deployments where model size is a constraint. It could also be integrated into existing pipelines to improve reference resolution capabilities.\n</text>\n</reference>",
  "output": "<summary>\nThe paper explores the field of reference resolution, which is crucial for understanding and managing various types of contextual information, including conversational and non-conversational entities. It demonstrates how large language models (LLMs) can be leveraged to address reference resolution by framing it as a language modeling problem. The research introduces a method to encode non-textual entities, such as on-screen elements, into a format that LLMs can process effectively. The approach shows significant improvements over traditional systems and achieves performance on par with or better than state-of-the-art models, while maintaining a smaller model size suitable for practical applications.\n</summary>"
}