{
  "input": "<reference id=\"WLQ7DVEC\">\n<metadata>\n{\n  \"title\": \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\",\n  \"abstract\": \"  We explore how generating a chain of thought -- a series of intermediate\\nreasoning steps -- significantly improves the ability of large language models\\nto perform complex reasoning. In particular, we show how such reasoning\\nabilities emerge naturally in sufficiently large language models via a simple\\nmethod called chain of thought prompting, where a few chain of thought\\ndemonstrations are provided as exemplars in prompting. Experiments on three\\nlarge language models show that chain of thought prompting improves performance\\non a range of arithmetic, commonsense, and symbolic reasoning tasks. The\\nempirical gains can be striking. For instance, prompting a 540B-parameter\\nlanguage model with just eight chain of thought exemplars achieves state of the\\nart accuracy on the GSM8K benchmark of math word problems, surpassing even\\nfinetuned GPT-3 with a verifier.\\n\",\n  \"published\": \"2022-01-28T02:33:07Z\"\n}\n</metadata>\n<text>\nSummary:\n\nThis paper introduces a technique called \"chain-of-thought prompting\" that significantly improves the reasoning abilities of large language models across a range of tasks, including arithmetic, commonsense reasoning, and symbolic manipulation. The key idea is to provide the model with a few exemplars that demonstrate a step-by-step \"chain of thought\" leading to the final answer, in addition to just the input-output pairs.\n\nThe main findings are:\n\n- Chain-of-thought prompting is an emergent ability that only appears in very large language models (>100B parameters). Smaller models fail to generate coherent chains of thought.\n\n- On arithmetic reasoning tasks like math word problems, chain-of-thought prompting enables models to outperform even finetuned, task-specific models, sometimes by a large margin. For example, PaLM 540B with chain-of-thought prompting achieves new state-of-the-art on the GSM8K benchmark.\n\n- Chain-of-thought prompting also improves performance on commonsense reasoning and symbolic manipulation tasks, by allowing the model to break down the problem into interpretable intermediate steps.\n\n- The generated chains of thought are not always factually correct, but they are generally coherent and can be used to arrive at the right answer. Improving the factuality of these chains of thought is an important direction for future work.\n\nKeywords: large language models, reasoning, prompting, chain of thought, arithmetic, commonsense, symbolic manipulation\n\nExample Questions:\n\nQ: How does the performance of phi-3-mini compare to state-of-the-art large language models when evaluated on standard academic NLP benchmarks?\nA: Phi-3-mini achieves performance rivaling much larger models like Mixtral 8x7B and GPT-3.5 on academic benchmarks, despite having only 3.8B parameters. This demonstrates the power of carefully curated training data to enable high quality in compact models.\n\nQ: What techniques were used to ensure phi-3-mini behaves in a safe, robust, and responsible manner during open-ended interactions with humans?\nA: The phi-3-mini model underwent an iterative process of safety alignment via finetuning on helpfulness and harmlessness preference datasets, red-teaming to identify potential issues, and extensive automated testing across dozens of responsibility and safety harm categories. However, challenges still remain in fully solving safety issues with language models.\n</text>\n</reference>",
  "output": "<summary>\nThe paper explores methods to enhance the reasoning capabilities of large language models by introducing a technique that involves providing step-by-step intermediate reasoning steps as part of the input. This approach significantly improves the models' performance on tasks requiring complex reasoning, such as arithmetic, commonsense reasoning, and symbolic manipulation. The technique is particularly effective in very large models, enabling them to break down problems into interpretable steps and achieve higher accuracy compared to traditional methods. The research highlights the potential of structured prompting to elicit more coherent and accurate reasoning in AI systems.\n</summary>"
}