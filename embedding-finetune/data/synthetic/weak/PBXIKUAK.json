{
  "input": "<reference id=\"PBXIKUAK\">\n<metadata>\n{\n  \"title\": \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your\\n  Phone\",\n  \"abstract\": \"  We introduce phi-3-mini, a 3.8 billion parameter language model trained on\\n3.3 trillion tokens, whose overall performance, as measured by both academic\\nbenchmarks and internal testing, rivals that of models such as Mixtral 8x7B and\\nGPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite\\nbeing small enough to be deployed on a phone. The innovation lies entirely in\\nour dataset for training, a scaled-up version of the one used for phi-2,\\ncomposed of heavily filtered web data and synthetic data. The model is also\\nfurther aligned for robustness, safety, and chat format. We also provide some\\ninitial parameter-scaling results with a 7B and 14B models trained for 4.8T\\ntokens, called phi-3-small and phi-3-medium, both significantly more capable\\nthan phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on\\nMT-bench).\\n\",\n  \"published\": \"2024-04-22T14:32:33Z\"\n}\n</metadata>\n<text>\nSummary:\nThis technical report introduces phi-3-mini, a compact 3.8 billion parameter language model that achieves performance rivaling much larger models like Mixtral 8x7B and GPT-3.5 on academic benchmarks and internal testing, while being small enough to run locally on a modern smartphone. The key innovation is in the training data, which consists of heavily filtered web data and synthetic data, similar to the approach used for phi-2. The model is also aligned for robustness, safety, and chat format. Initial scaling results with 7B and 14B parameter models (phi-3-small and phi-3-medium) show significant further performance gains.\n\nDespite its small size, phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench. The model's main limitation is factual knowledge due to capacity constraints, but this can be mitigated by augmenting it with a search engine. Safety and responsibility were key focuses, with the model undergoing safety alignment, red-teaming, and automated testing. However, challenges remain around factual inaccuracies, bias, inappropriate content, and safety issues that still need to be fully addressed.\n\nKeywords: compact language models, filtered training data, on-device inference, model scaling, responsible AI\n\nExample Questions:\nQ: How does the performance of phi-3-mini compare to state-of-the-art large language models when evaluated on standard academic NLP benchmarks?\nQ: What techniques were used to ensure phi-3-mini behaves in a safe, robust, and responsible manner during open-ended interactions with humans?\nQ: How might the ability to run highly capable language models like phi-3-mini directly on consumer devices change the way AI assistants are developed and deployed in the future?\nQ: What are some potential beneficial applications of a model like phi-3-mini that can perform advanced language tasks while preserving user privacy by running fully on-device?\n</text>\n</reference>",
  "output": "<note>\nToday was an exciting day at work as we continued to make progress on our latest AI project. The team has been working hard to integrate a compact language model called phi-3-mini into our mobile app, and the results so far have been really promising.\n\nWhat's remarkable about phi-3-mini is that despite its relatively small size, it's able to match the performance of much larger models on a variety of academic benchmarks. The team has done an impressive job optimizing the training data and model architecture to achieve this level of capability in a package that can run directly on a user's phone. It's a testament to how far the field of AI has come.\n\nOf course, deploying a highly capable language model like this comes with its own set of challenges. We've had to put a lot of thought into ensuring the model behaves in a safe and responsible manner, with robust safeguards against potential misuse or unintended consequences. The team has been working closely with our ethics board to implement rigorous testing and alignment procedures.\n\nOne of the most exciting aspects of this project is the potential impact it could have on the way people interact with AI assistants in the future. Imagine being able to access the power of large language models without having to worry about privacy or data security issues. With phi-3-mini running locally on your device, you could engage in natural conversations, get help with tasks, and even explore creative endeavors, all while keeping your personal information safe.\n\nIt's been a long road to get to this point, but the team is energized by the progress we've made. There's still a lot of work to be done, but I'm confident that we're on the right track. I can't wait to see what the future holds for this technology and how it will continue to shape the way we interact with the digital world.\n</note>"
}