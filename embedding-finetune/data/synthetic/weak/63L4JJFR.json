{
  "input": "<reference id=\"63L4JJFR\">\n<metadata>\n{\n  \"title\": \"Large Language Models as Optimizers\",\n  \"abstract\": \"  Optimization is ubiquitous. While derivative-based algorithms have been\\npowerful tools for various problems, the absence of gradient imposes challenges\\non many real-world applications. In this work, we propose Optimization by\\nPROmpting (OPRO), a simple and effective approach to leverage large language\\nmodels (LLMs) as optimizers, where the optimization task is described in\\nnatural language. In each optimization step, the LLM generates new solutions\\nfrom the prompt that contains previously generated solutions with their values,\\nthen the new solutions are evaluated and added to the prompt for the next\\noptimization step. We first showcase OPRO on linear regression and traveling\\nsalesman problems, then move on to our main application in prompt optimization,\\nwhere the goal is to find instructions that maximize the task accuracy. With a\\nvariety of LLMs, we demonstrate that the best prompts optimized by OPRO\\noutperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on\\nBig-Bench Hard tasks. Code at https://github.com/google-deepmind/opro.\\n\",\n  \"published\": \"2023-09-07T00:07:15Z\"\n}\n</metadata>\n<text>\nSummary:\n\nThis paper introduces OPRO (Optimization by PROmpting), a novel approach to leverage large language models (LLMs) as optimizers. The key idea is to describe the optimization task in natural language, and then have the LLM iteratively generate new solutions based on the prompt containing the previous solutions and their scores.\n\nThe paper first showcases OPRO on linear regression and traveling salesman problems, demonstrating that LLMs can optimize these tasks simply through prompting, sometimes matching or surpassing specialized algorithms. \n\nThe main application of OPRO is prompt optimization, where the goal is to find prompts that maximize the task accuracy on natural language benchmarks. The authors show that OPRO can significantly outperform human-designed prompts, improving accuracy by up to 8% on GSM8K and up to 50% on Big-Bench Hard tasks. This is achieved by having the LLM leverage the optimization trajectory, where past prompts and their scores are used to guide the generation of new, higher-performing prompts.\n\nThe paper also provides detailed ablation studies on the key components of the meta-prompt design, and analyzes the potential overfitting issue in prompt optimization. Comparisons to concurrent work on prompt optimization, such as EvoPrompt, are also presented.\n\nOverall, this work demonstrates the potential of using LLMs as general-purpose optimizers, beyond their traditional applications in language tasks. The ability to optimize prompts through natural language interaction opens up new possibilities for making advanced AI capabilities more accessible.\n\nKeywords: large language models, optimization, prompt engineering, prompt optimization\n\nExample Questions:\nQ: How does OPRO leverage the optimization trajectory to guide the LLM in generating better prompts over time?\nA: OPRO includes the past prompts and their scores in the meta-prompt, allowing the LLM to identify patterns in high-performing prompts and build upon them to generate new, improved prompts. This is in contrast to approaches that only consider a single prompt at a time.\n\nQ: What are some of the key design choices in the meta-prompt that were found to be important for the effectiveness of OPRO in prompt optimization?\nA: The ablation studies show that factors like the order of previous prompts, the inclusion of accuracy scores, and the number of exemplars in the meta-prompt can significantly impact the optimization performance. For example, presenting the prompts in ascending order of scores, and including the accuracy scores, were found to be important for the LLM to effectively exploit the optimization trajectory.\n\nQ: How does OPRO's approach to prompt optimization differ from concurrent work like EvoPrompt, and what are the advantages of OPRO's approach?\nA: Unlike EvoPrompt, which relies on explicit instructions for mutation and crossover of prompts, OPRO allows the LLM to directly generate new prompts based on the optimization trajectory. This gives the LLM more flexibility to discover patterns and generate prompts that improve upon the past ones, without being constrained by predefined operations. OPRO also provides richer information in the meta-prompt, such as exemplars and accuracy scores, which was shown to be beneficial for the LLM's optimization performance.\n</text>\n</reference>",
  "output": "<note>\nToday was an exciting day at work as we continued to explore the potential of using large language models (LLMs) as optimizers. I spent the morning diving deeper into the OPRO (Optimization by PROmpting) approach that we've been experimenting with.\n\nThe idea of leveraging LLMs to solve optimization problems through natural language prompting is just fascinating to me. I've been playing around with the technique on a few different tasks, and the results have been really promising. For example, we were able to use OPRO to optimize prompts for some of our natural language benchmarks, and the performance improvements were quite significant - up to 8% on GSM8K and 50% on the Big-Bench Hard tasks.\n\nWhat's really interesting is how the LLM is able to learn from the optimization trajectory, using the previous prompts and their scores to guide the generation of new, higher-performing prompts. It's almost like the model is developing its own intuition for what makes a good prompt, rather than just blindly trying different variations. The meta-prompt design seems to be a key factor in this, with things like the order of previous prompts and the inclusion of accuracy scores making a big difference.\n\nIn the afternoon, I had a chance to compare OPRO to some of the other prompt optimization approaches that have been proposed, like EvoPrompt. I can see the advantages of OPRO's more flexible, LLM-driven approach compared to the more rigid, rule-based methods. It really opens up the possibility of making advanced AI capabilities more accessible, by allowing users to simply describe their optimization problems in natural language and let the LLM handle the heavy lifting.\n\nAs I was wrapping up for the day, I couldn't help but wonder about the broader implications of this work. Optimization is such a fundamental problem in so many domains, from engineering to finance to scientific research. If we can harness the power of LLMs to tackle these challenges in a more intuitive and accessible way, it could have a huge impact. Of course, there's still a lot of work to be done, but the potential is really exciting.\n\nI'm looking forward to seeing how this project evolves and what new insights we'll uncover. It's been a long day, but I'm energized and ready to dive back in tomorrow.\n</note>"
}